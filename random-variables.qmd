# Random variables {#sec-random-variables}

```{r}
#| include: false

source("_common.R")
```

:::{.underconstruction data-latex="}

Incomplete draft, possible additions and corrections pending

:::

:::{.todo data-latex=""}

- Exercises are incomplete.

- No chapter summary

:::


::: {.chapterintro data-latex=""}
Data are the result of a study. The study might have been an experiment or observational study, and the data collected using the methods discussed in @sec-collecting-data. **Random variables** \index{random variable} connect the important concepts of recording measurements and probability: a random variable assigns numerical values to the outcome of a random phenomenon and the distribution of the variable reflects the variability in outcomes. 

Random variables are usually written with a capital letter such as $X$, $Y$, or $Z$ and are characterized as either discrete or continuous. This chapter outlines general properties of random variables and their distributions. The next chapter discusses some specific random variables that often arise in practice.
:::

```{r}
#| include: false
terms_chp_4 <- c("random variable (RV)")
```

## Discrete random variables {#sec-discrete-rv}

If a coin is tossed three times, the outcome of the process is the sequence of observed heads and tails. One such outcome might be TTH: tails on the first two tosses, heads on the third. If the random variable $X$ is the number of heads for the three tosses, $X=1$; if $Y$ is the number of tails, then $Y=2$. For the sequence THT, only the order has changed, but the values of $X$ and $Y$ remain the same. For the sequence HHH, however, $X=3$ and $Y=0$. The values of $X$ and $Y$ will vary each time the process of tossing the coin three times is repeated. 

```{r three-coin-tosses}
#| label: fig-coin-toss
#| out-width: 70%
#| fig-cap: 	Possible outcomes for number of heads in three tosses of a coin.
#| fig-alt:   draft alt caption here
#| fig-pos: H
library(ggplot2)
library(dplyr)
library(tidyr)

# plot constructed by iterating with ChatGPT 5.0
#--- helper to turn a 3×3 character matrix into a tidy data frame -------------
grid_to_df <- function(mat, panel_label){
  stopifnot(all(dim(mat) == c(3,3)))
  as.data.frame(mat, stringsAsFactors = FALSE) |>
    mutate(y = 3:1) |>
    pivot_longer(-y, names_to = "x", values_to = "face") |>
    mutate(x = match(x, colnames(mat)), 
           panel = panel_label)
}

# Panel 1 (three T’s)
p1 <- tibble(
  panel = "X = 0",
  x = 1:3,
  y = 1,
  face = "T"
)

# Panel 2 and 3 (3×3 grids)
grid2 <- matrix(c(
  "T","T","H",
  "T","H","T",
  "H","T","H"
), nrow = 3, byrow = TRUE,
dimnames = list(NULL, c("x1","x2","x3")))

grid3 <- matrix(c(
  "T","H","H",
  "H","T","H",
  "H","H","T"
), nrow = 3, byrow = TRUE,
dimnames = list(NULL, c("x1","x2","x3")))

p2 <- grid_to_df(grid2, "X = 1")
p3 <- grid_to_df(grid3, "X = 2")

# Panel 4 (three H’s)
p4 <- tibble(
  panel = "X = 3",
  x = 1:3,
  y = 1,
  face = "H"
)

# Combine all panels
df <- bind_rows(p1, p2, p3, p4) |>
  mutate(panel = factor(panel, levels = c("X = 0","X = 1","X = 2","X = 3")),
         y_plot = y)

# Final plot
ggplot(df, aes(x = x, y = y_plot)) +
  # white footer bar
  annotate("rect", xmin = -Inf, xmax = Inf, ymin = 0, ymax = 0.6, fill = "white") +
  # coin outlines
  geom_point(shape = 21, size = 18, stroke = 1.2, fill = "white", color = "#2E6FDF") +
  # H/T letters
  geom_text(aes(label = face), size = 6, color = "#2E6FDF", fontface = "bold") +
  # facet labels BELOW the panels
  facet_wrap(~panel, nrow = 1, strip.position = "bottom") +
  scale_x_continuous(limits = c(0.5, 3.5), breaks = 1:3) +
  scale_y_continuous(limits = c(0, 3.6), breaks = 1:3) +
  coord_fixed() +
  theme_minimal(base_size = 13) +
  theme(
    panel.background = element_rect(fill = "#F3F3F3", color = NA),
    panel.spacing = unit(0, "pt"),              # replaces deprecated panel.margin
    strip.background = element_rect(fill = "white", color = "black"),
    strip.text = element_text(size = 14, face = "bold", color = "black"),
    strip.placement = "outside",
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    plot.margin = margin(0, 0, 0, 0),
    panel.grid = element_blank()
  )

```

The probabilities  assigned to the outcomes in a random phenomenon are used to assign probabilities to values of a random variable. Using independence, $P(\text{HHH}) = (1/2)^3 = 1/8$. Since $X$ in the above example can only be three if the three tosses are all heads, $P(X=3) = 1/8$. The distribution of a random variable is the collection of probabilities for all of the variable's possible values. @fig-coin-toss shows the eight possible outcomes when a coin is tossed three times: TTT, HTT, THT, TTH, HHT, HTH, THH, HHH. For the first set of tosses, $X = 0$; for the next three, $X=1$, then $X=2$ for the following three tosses and $X=3$ for the last set (HHH).

Using independence again, each of the 8 outcomes have probability 1/8, so $P(X = 0) = P(X = 3) = 1/8$ and $P(X = 1) = P(X = 2) = 3/8$. @tbl-dist-coin-tossing shows the probability distribution for $X$. Probability distributions for random variables follow the rules for probability; for instance, the probabilities must be between 0 and 1 and their sum must be 1. The possible outcomes of $X$ are labeled with a corresponding lower case letter $x$ and subscripts. The values of X are $x_1 = 0$, $x_2 = 1$, $x_3 = 2$, and $x_4 = 3$; these occur with probabilities $1/8$, $3/8$, $3/8$ and $1/8$.

|     $i$      |  1  |  2  |  3  |  4  |      Total |
|:------------:|:---:|:---:|:---:|:---:|-----------:|
|    $x_i$     |  0  |  1  |  2  |  3  |         -- |
| $P(X = x_i)$ | 1/8 | 3/8 | 3/8 | 1/8 | 8/8 = 1.00 |

: Tabular form for the distribution of the number of heads in three coin tosses. {#tbl-dist-coin-tossing}

**Bar plots** can be used to show the distribution of a random variable. @fig-bar-plot-coin-tossing is a bar plot of the distribution of $X$ in the coin tossing example. When bar plots are used to show the distribution of a dataset, the heights of the bars show either the frequency or relative frequency of each observation of the variable in the dataset. In contrast, bar heights for a probability distribution show the probabilities of possible values of a random variable before any observations have been made.

```{r bar-plot-coin-tossing}
#| label: fig-bar-plot-coin-tossing
#| fig-cap: Bar plot of the distribution of the number of heads in three coin tosses.
#| fig-alt: |
#|   coming 
#| fig-width: 4

# Create the data frame
x.df <- data.frame(
  x.values = c(0, 1, 2, 3),
  x.probs = c(1/8, 3/8, 3/8, 1/8)
)

ggplot(x.df, aes(x = x.values, y = x.probs)) +
  geom_col(fill = IMSCOL["blue", "full"], 
           width = 0.5,
           position = "dodge") +
  labs(
    x = "Number of Heads (X)",
    y = "Probability"
  ) +
  theme(
    axis.title.x = element_text(size = 8),  # X-axis title size
    axis.title.y = element_text(size = 8),  # Y-axis title size
    axis.text.x  = element_text(size = 8),  # X-axis tick labels
    axis.text.y  = element_text(size = 8)   # Y-axis tick labels
  )
```

$X$ is an example of a **discrete random variable** \index{discrete random variable} -- a variable taking on a finite number of values  -- and its distribution.[^random-variables-1]

[^random-variables-1]: Some discrete random variables have an infinite number of possible values, such as all the non-negative integers.

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4,
                 "discrete RV",
                 "bar plots")
```

### Distribution of a discrete random variable

::: {.important data-latex=""}
**Distribution of a discrete random variable.**

The distribution of a discrete random variable $X$ is the set of its possible values $x_1, x_2, \dots, x_k$ and the associated probabilities $P(x_1), P(x_2), \ldots , P(x_k)$. It must satisfy the following conditions:

-   $0 \leq P(x_i) \leq 1.$

-   $P(x_1) + P(x_2) + \dots + P(x_k) = \sum_{i=1}^{k} P(X=x_i) = 1$

Distributions of discrete random variables are usually specified in tables, such as @tbl-dist-coin-tossing, or bar plots such as @fig-bar-plot-coin-tossing.
:::

::: {.workedexample data-latex=""}
Suppose a random process consists of rolling two six-sided dice. (a) Create a table showing the possible outcomes of the roll and the probability distribution of the sum of the faces. (b) Show the distribution in a bar graph.

------------------------------------------------------------------------

(a) The first column of @tbl-sum-two-dice shows all 36 possible values of the roll of two dice, the sum for each value, and the associated probability of the value of the sum under the assumption that all 36 outcomes of the roll are equally likely.

| Possible values of the two dice          | Sum | Probability  |
|:-----------------------------------------|:----|:-------------|
| (1,1)                                    | 2   | 1/36 = 0.029 |
| (1,2), (2,1)                             | 3   | 2/36 = 0.056 |
| (1,3), (2,2), (3,1)                      | 4   | 3/36 = 0.083 |
| (1,4), (2,3), (3,2), (4,1)               | 5   | 4/36 = 0.111 |
| (1,5), (2,4), (3,3), (4,2), (5,1)        | 6   | 5/36 = 0.139 |
| (1,6), (2,5), (3,4), (4,3), (5,2), (6,1) | 7   | 6/36 = 0.167 |
| (2,6), (3,5), (4,4), (5,3), (6,2)        | 8   | 5/36 = 0.139 |
| (3,6), (4,5), (5,4), (6,3)               | 9   | 4/36 = 0.111 |
| (4,6), (5,5), (6,4)                      | 10  | 3/36 = 0.083 |
| (5,6), (6,5)                             | 11  | 2/36 = 0.056 |
| (6,6)                                    | 12  | 1/36 = 0.029 |

: Probability distribution for the sum of two dice {#tbl-sum-two-dice}

(b) @fig-sum-two-dice is a bar graph in which the height of each bar is the probability of the corresponding value of the sum. The graph shows that the distribution is symmetric, with a mode at 7.

```{r sum-two-dice}
#| label: fig-sum-two-dice
#| out-width: 70%
#| fig-cap: | 
#|     Bar graph showing the probability distribution for the sum of two dice.

# Create data frame for the distribution
dice_data <- data.frame(
  Sum = 2:12,
  Probability = c(1,2,3,4,5,6,5,4,3,2,1) / 36
)

# Create bar plot
ggplot(dice_data, aes(x = factor(Sum), y = Probability)) +
  geom_bar(stat = "identity", 
           fill = IMSCOL["blue", "full"]) +
  labs(x = "Sum of the two dice",
       y = "Probability") 
```
:::

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4,
                 "distribution of discrete RV")
```
## Continuous random variables {#sec-continuous-rv}

Measurements of human characteristics such as height, weight, or systolic blood pressure are not limited to a finite number of discrete values. They can take on all values within a certain range. **Continuous random variables** \index{continuous random variable} are used to model or represent these types of measurements. For the discrete random variables discussed earlier, such as the sum of two dice, it was possible to specify a random phenomenon or process that gave rise to the distribution of a variable, such as in @tbl-sum-two-dice. That is rarely possible with continuous random variables; the phenomena that lead to variations in weight, for instance, are not well-enough understood. Instead, the distributions of continuous variables are often chosen to match historical data.

```{r}
library(nhanesA)
library(dplyr)
library(ggplot2)

#  BMX_J is 2021 - 2023 pre-pandemic cycle
bmx  <- nhanes("BMX_L")   # Body Measures
demo <- nhanes("DEMO_L")  # Demographics

bmx_demo <- inner_join(bmx, demo, by = "SEQN")

adult_wt_ht <- bmx_demo |> 
  filter(RIDAGEYR >= 18,
         !is.na(BMXWT),
         !is.na(BMXHT),
         !is.na(RIAGENDR),
         BMXWT > 0,
         BMXHT > 0) |> 
  select(BMXWT, BMXHT, RIAGENDR) 

```

```{r}
nw <- nrow(adult_wt_ht)
mu_w <-round(mean(adult_wt_ht$BMXWT), 2)
med_w <-round(median(adult_wt_ht$BMXWT), 2)

```

@fig-adult-wt-box-hist-prop shows the distribution of the weight in kilograms (kg) of `r nw` members of the US population. The data come from the National Health and Nutrition Examination Survey (NHANES) conducted between 2021 and 2023. Both the box plot and the histogram show that the distribution is skewed right with many outliers; the mean weight (`r mu_w`) is larger than the median (`r med_w`). The graph shows that it would be inappropriate to think of weights as symmetrically distributed.  

The minimum and maximum observed weights are `r min(adult_wt_ht$BMXWT)`kg and `r max(adult_wt_ht$BMXWT)`kg. ^[The maximum weight in the data is certainly large, but human weights have been recorded as large as 500 - 600kg.]  The histogram shows relative frequencies, so the heights of the bars represent the fraction of the observations found in each interval of width 5kg. For instance, approximately 3.8%, or 0.0375, of the weights are between 50 and 55kg, and another 6.3% are between 55 and 60kg, so approximately 10.1% are between 50 and 60kg. 

Both plots illustrate that the middle 50% of weights of US adults is approximately symmetric but overall the distribution skews toward being overweight or obese, a tendency that has been widely studied in the US population.  What random variable $W$ might be used to model this distribution?


```{r}
#| label: fig-adult-wt-box-hist-prop
#| out-width: 80%
#| fig-cap: | 
#|     Distribution of weights (kg) US adults 18 or older.


library(patchwork)

p1 <- ggplot(adult_wt_ht, aes(x = BMXWT)) +
  geom_boxplot() +
  scale_color_openintro("two") +
  labs(y = NULL, x = NULL) +
  theme(
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
   # plot.margin = margin(b = 0)
  ) 
#  scale_x_continuous(breaks = seq(0, 220, 50)) 

p2 <- ggplot(adult_wt_ht, aes(x = BMXWT)) +
  geom_histogram(aes(y = after_stat(count / sum(count))),
         breaks = seq(0, 225, 5),
         closed = "right") +
     labs(x = "Weight (kg)", y = "Proportion") +
     scale_x_continuous(
    breaks = seq(0, 220, 50))+
    scale_y_continuous(breaks = seq(0, 0.10, 0.0125))

p1/p2 + plot_layout(heights = c(0.25, 0.75))

```

The histogram in @fig-adult-wt-hist-density uses the same data as @fig-adult-wt-box-hist-prop but is drawn on a **density scale** \index{density scale}. The vertical axis has been re-scaled so that the height of the bars is now the proportion of observations divided by the width of the bins (5kg in this case). When a histogram is drawn on the density scale, the proportion of observations falling in a bin is now the area of the bar, since multiplying the density value by the bin width recovers the proportion. For instance, the probability that a weight is between 50 and 60kg can be read directly from the plot as a little larger than 0.010. Since proportions like probabilities add to 1, the total area under the histogram drawn on a density scale will be 1.

A random variable $W$ that might be used to model weights should reflect the shape of the histogram, but "smooth out" the features of the data from the sample of `r nw` observations.  The smooth red curve in the plot is the best fitting smooth **density curve** \index{density curve} to the histogram where the total area under the curve is 1. The extended right tail in the curve reflects the large weights that occur in small numbers. Since the curve approximates the histogram, the probability of an observation in a range of heights will be approximately the area under the density curve in that range of heights.

```{r}
#| label: fig-adult-wt-hist-density
#| out-width: 70%
#| fig-cap: | 
#|     Histogram of the weights (kg) adults 18 years or older from NHANES, density scale.

ggplot(adult_wt_ht, aes(x = BMXWT)) +
  geom_histogram(aes(y = after_stat(density)),
                 breaks = seq(0, 225, 5),
                 closed = "right") +
     labs(x = "Weight (kg)", y = "Density") +
     scale_x_continuous(
    breaks = seq(0, 220, 50)) +
   geom_density(
    color = "red",
    linewidth = 1.0,
    alpha = 0.8,
    bw = 5.5
  ) 

```

If the NHANES data are approximately representative of the US adult population, the density function shows the distribution of a continuous  random variable $W$ representing the weight of a randomly sampled individual from the US population.  Unlike a discrete random variable, where distributions can be displayed in a table, the distribution of continuous random variable is summarized in a **probability density function** \index{probability density function}.

::: {.important data-latex=""}
**Probability density function.**

The probability density function $f(x)$ of a continuous random variable $X$ is a curve that satisfies:

-   The values of $f(x)$ are non-negative.

-   The total area under the curve $f(x)$ is 1.^[Using calculus notation, $\int f(x)dx = 1$]

-   The probability that $X$ has a value between two numbers $a$ and $b$, $P(a \leq X \leq b)$, is the area under $f(x)$ between $x = a$ and $x = b$.
:::

The probability density function in @fig-adult-wt-density-fit is a theoretical density function for a random variable $W$ that can be used to model the distribution of observed weights from randomly selected members of the US adult population. The shaded area under the curve between 50 and 60kg is 0.102, close to the earlier values estimated from the histogram drawn on the proportion scale. Software is generally used to calculate area under a density curve. For the purposes of this text, however, the concept of a density function is more important than the details of how to calculate probabilities. It is important to remember that areas are used to calculate probabilities with a density function, not the height of the curve.

```{r}
#| label: fig-adult-wt-density-fit
#| out-width: 70%
#| fig-cap: | 
#|     Smooth density function matching the distribution of weights.  Area of the shaded region is the probability of observing a weight between 50 and 60 kg.
p <- ggplot(adult_wt_ht, aes(BMXWT)) +
        geom_density(bw = 5.5)
pb <- ggplot_build(p)
curve <- pb$data[[1]][, c("x", "y")]  # density grid used by ggplot

a <- 50; b <- 60
dx <- diff(curve$x)[1]
area_ab <- sum(curve$y[curve$x >= a & curve$x <= b]) * dx

ggplot(curve, aes(x, y)) +
  geom_line(linewidth = 1.0) +
  geom_area(
    data = subset(curve, x >= a & x <= b),
    fill = IMSCOL["blue", "full"], alpha = 0.75
  ) +
  labs(
    x = "Weight (kg)", y = "Density") +
    scale_x_continuous(
    breaks = seq(0, 220, 50))

```

::: {.workedexample data-latex=""}
What is the probability that a randomly selected person weighs **exactly** 53.47 kg? Assume that weight can be measured perfectly.

------------------------------------------------------------------------

This probability is zero. A person's weight might be close to 53.47kg, but not exactly that value. This is consistent with the definition of probability as an area under the density curve; there is no area captured above a single point.
:::

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4,
                 "continuous RV",
                 "density scale",
                 "density function",
                 "area under a density function")
```

## Expected value of a random variable {#sec-expected-value-rv}

Just like distributions of data, distributions of random variables have means, variances, and standard deviations; these characteristics are computed a bit differently for random variables but have the same interpretation. The mean of a random variable is called its **expected value** \index{expected value} and written $E(X)$. It is computed differently for discrete and continuous random variables but it has the same interpretation in both cases.

### Expected value of a discrete random variable {sec-expected-value-discrete-rv}

::: {.important data-latex=""}
If $X$ is a discrete variable taking on the $k$ values $x_1 \ldots x_k$ with probabilities $P(X=x_1) \ldots P(X=x_k)$, the expected value of $X$ is the sum of each value multiplied by its corresponding probability:

$$
\begin{aligned}
E(X)  &= x_1 P(X=x_1) + \cdots + x_k P(X=x_k) \\
      &= \sum_{i=1}^{k} x_i P(X=x_i).
\end{aligned}
$$ {#eq-expectation-discrete-rv}

The Greek letter $\mu$\index{Greek!mu ($\mu$)} may be used in place of the notation $E(X)$. The expected value of $X$ is sometimes written $\mu_X$ to eliminate ambiguity.
:::


::: {.workedexample data-latex=""}

Calculate the expected value of $X$, where $X$ represents the number of heads in three tosses of a fair coin.

------------------------------------------------------------------------

$X$ can take on the four values 0, 1, 2, and 3. The probability of each value $x_k$ is given in @tbl-dist-coin-tossing.

\begin{align*}
E(X) &= x_1 P(X = x_1) + \dots + x_k P(X = x_k)\\
&= (0)(P(X=0)) + (1)(P(X=1)) + (2)(P(X=2)) + (3)(P(X = 3)) \\
&= (0)(1/8) + (1)(3/8) + (2)(3/8) + (3)(1/8) = 12/8 \\
&= 1.5.
\end{align*}

The expected value of $X$ is 1.5.
:::

The expected value for a random variable represents the average outcome. For example, $E(X)=1.5$ represents the average number of heads in three tosses of a coin, if the three tosses were repeated many times. With discrete random variables the expected value need not be one of the possible outcomes of the variable, as in this example.

::: {.guidedpractice data-latex=""}
Calculate the expected value of $Y$, where $Y$ represents the number of heads in three tosses of an unfair coin, where the probability of heads is 0.70. [^random-variables-3]
:::

[^random-variables-3]: First, calculate the probability distribution of $Y$. $P(Y=0) = (1 - 0.70)^3 = 0.027$ and $P(Y=3) = (0.70)^3 = 0.343.$ Note that there are three ways to obtain 1 head (HTT, THT, TTH), thus, $P(Y=1) = (3)(0.70)(1 - 0.70)^2 = 0.189$. By the same logic, $P(Y = 2) = (3)(0.70)^2( 1- 0.70) = 0.441$. Thus, $E(Y) = (0)(0.027) + (1)(0.189) + (2)(0.441) + (3)(0.343) = 2.1$. The expected value of $Y$ is 2.1.

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4,
                 "expected value"
                 )
```

### Expected value of a continuous random variable {#sec-expected-value-continuous-rv}


```{r mean-sd-adult-weights}

dens <- density(adult_wt_ht$BMXWT)
df <- data.frame(x = dens$x, y = dens$y)

# Mean of the density estimate
mean_kde <- round(sum(df$x * df$y) / sum(df$y), 1)

# Variance of the density estimate
var_kde <- round(sum((df$x - mean_kde)^2 * df$y) / sum(df$y), 2)
sd_kde <- round(sqrt(var_kde), 2)


```

Expected values of continuous random variables are calculated using either calculus or software, so there are no formulas like @eq-expectation-discrete-rv. But the expected value of a continuous random variable does have a concrete interpretation. Think of the area under a density curve as a distribution of weight or mass, with larger values of the density indicating more mass. The expected value $\mu$ of a continuous random variable is the point on the horizontal axis where the density would balance. @fig-chi-sq-density-with-mean illustrates that concept.[^random-variables-4]

[^random-variables-4]: This is figure 3.21 in [OpenIntro Statistics, 4^th^ ed.](https://www.openintro.org/book/os/)

When the density is skewed right with a heavy tail, the balance point moves right to maintain the balance.

```{r}
#| label: fig-chi-sq-density-with-mean
#| out-width: 70%
#| fig-cap: | 
#|     A theoretical probability density function with mean $\mu$.  If the density represents a distribution of mass, it will balance at the value $\mu$ on the horizontal axis.
x <- seq(0, 22, 0.01)
y <- dchisq(x, 5)
M <- weighted.mean(x, y)

par(mar = c(1.65, 0, 0, 0), mgp = c(5, 0.5, 0))
plot(x, y + 0.035,
     type = 'l',
     ylim = range(c(0.025, y + 0.035)),
     axes = FALSE)
axis(1, at = c(-100, M, 100), labels = c('', expression(mu), ''))
lines(c(0, 22), rep(0.035, 2))
polygon(x, y + 0.035, col = IMSCOL["blue", "full"])
polygon(c(M - 20, M + 20, M),
        c(-0.2, -0.2, 0.035),
        col = COL[4])


```

@fig-weight-density-with-mean illustrates the idea with the density function of $W$ used to model the distribution of weights NHANES. Values on the x-axis are not shown, but the balance point is $E(W)$ = `r mean_kde`kg.

```{r}
#| label: fig-weight-density-with-mean
#| out-width: 80%
#| fig-cap: | 
#|     The probability density function for the weights $W$ with mean $\mu_W$ = 82.9kg. 
M <- mu_w
tri_df <- data.frame(
  x = c(M - 12, M + 12, M),
  y = c(-0.002, -0.002, 0.0)   # base well below, tip touches baseline
)
ggplot(adult_wt_ht, aes(BMXWT)) +
    geom_density(bw = 5.5,
                    fill = IMSCOL["blue", "full"],
                    alpha = 1.0,
                    color = "black") +
    annotate(
             "segment",
              x = 0, xend = 250, 
              y = -0.002, yend = -0.002,
              color = "black", 
             linewidth = 0.4) +
   annotate(
           "segment",
           x = M, xend = M,
           y = - 0.003, yend = -0.002,   # short vertical line
           color = "black", linewidth = 0.4
  ) +
    geom_polygon(
                data = tri_df,
                aes(x = x, y = y),
                fill = IMSCOL["red", "full"],
                inherit.aes = FALSE) +
    scale_x_continuous(limits = c(0, 250),
                     breaks = M,
                     labels = c(expression(mu))) +
    labs(x = NULL, y = NULL) +  
    theme(
    axis.title = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.grid = element_blank()
  )
        
```



## Variance and standard deviation of a random variable {#sec-variance-rv}

The variability of a random variable can be described by its \index{variance} **variance** and \index{standard deviation} **standard deviation**. For a dataset with $n$ observations, the variance is computed by squaring deviations from the mean of the data, $(x_i - \bar{x})^2,$  then computing the average those deviations using a denominator of $n - 1$. (See @sec-summarizing-numerical-data.) 

In the case of a random variable, the squared deviations from the mean $\mu$ are used instead of from the sample mean $\bar{x}$, and the average is a weighted average using the corresponding probabilities. This weighted sum of squared deviations defines the variance of the random variable; the standard deviation is the square root of the variance.

::: {.important data-latex=""}

### Variance of a discrete random variable {#sec-variance-discrete-rv}

If $X$ takes on the $k$ outcomes $x_1$, ..., $x_k$ with probabilities $P(X=x_1)$, \dots, $P(X=x_k)$ and has expected value $\mu=E(X)$, then the variance of $X$, denoted by $\text{Var}(X)$ or $\sigma^2$, is
$$
\begin{aligned}
\text{Var}(X) &= (x_1-\mu)^2 P(X=x_1) + \cdots \notag + (x_k-\mu)^2 P(X=x_k) \notag \\
&= \sum_{i=1}^{k} (x_i - \mu)^2 P(X=x_i).
\end{aligned}
$${#eq-variance-discrete-rv}

The standard deviation of $X$, labeled $\text{SD}(X)$ or $\sigma$ \index{Greek!sigma ($\sigma$)}, is the square root of the variance. The standard deviation is sometimes written as $\sigma_X$ to eliminate ambiguity.  The standard deviation has the same units of measurements as the original observations.

:::
 
The variance of a random variable can be interpreted as the expectation of the terms $(x_i - \mu)^2$; i.e., $\sigma^2 = E(X - \mu)^2$. While this compact form is not useful for direct computation, it can be helpful for understanding the concept of variability of a random variable; variance is simply the average of the squared deviations from the mean, just as it is when calculating the variance of observations in a dataset.

::: {.workedexample data-latex=""}

Compute the variance and standard deviation of $X$, the number of heads in three tosses of a fair coin.

------------------------------------------------------------------------

In the formula for the variance, $k = 4$ and $\mu_X = E(X) = 1.5$. 
\begin{align*}
	\sigma_X^2 &= (x_1-\mu_X)^2P(X=x_1) + \cdots + (x_4-\mu)^2 P(X=x_4)  \\
	&= (0- 1.5)^2(1/8) + (1 - 1.5)^2 (3/8) + 
	(2 -1.5)^2 (3/8) + (3-1.5)^2 (1/8) \\
	&= 3/4.
\end{align*}
The variance is $3/4 = 0.75$ and the standard deviation is $\sigma = \sqrt{3/4} = 0.866$. 
:::

The coin tossing scenario provides a simple illustration of the mean and variance of a random variable. A more realistic example is discussed in For the rest of this section, a more realistic example will be discussed -  calculating expected health care costs.

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4, 
               c("variance of an RV",
                 "standard deviation of an RV")
)
```

### The variance of a continuous random variable {#sec-variance-continuous-rv}


The variance of a continuous random variable has the same interpretation as that of a discrete variable -- it is the average of the squared deviation of each value from the mean.

::: {.important data-latex=""}
**Name.**

Suppose $X$ is a continuous random variable with mean $\mu = E(X)$.  The variance of $X$ is ^[The calculus based definition is  $\text{Var}(X) = \int (x - \mu)^2 f(x)dx$, but that is not needed in this text and can be ignored.]
$$
 \text{Var}(X) = E(X - \mu)^2,
$$
and its standard deviation is 
$$
  \sigma_X = \sqrt{\text{Var}(X)}.
$$
:::


The calculations are not shown here, but the variance and standard deviation of adult weights in the NHANES data are `r var_kde`kg^2^ and `r sd_kde`kg, respectively.  


## Sums of random variables {#sec-sums-rv}

Sums of random variables arise naturally in many problems. When rolling two dice, the total $X$ shown on the roll is the sum of the two faces showing, $X_1 + X_2$.  If $Y$ is the total time commuting to work during a 5-day work week, $Y = Y_1 + Y_2 + \cdots +Y_5$, where the individual $Y$ values represent the commuting time for each of the 5 days.

Sums of random variables represent a special case of linear combinations of variables.  

::: {.important data-latex=""}
**The expected value of a sum of random variables.**

Suppose $X$ and $Y$ are random variables.  Then 

$$
E(aX + bY) = aE(X) + bE(Y) = a\mu_X + b\mu_Y.
$$ {#eq-mean-linear-combination-rv}

:::

The formula easily generalizes to a sum of any number of random variables.  The expected time commuting during the week will be 
$$
  E(Y) = E(Y_1) + E(Y_2) + \cdots + E(Y_5).
$$

The formula implies that for a random variable $Z$, $E(a + Z) = a + E(Z)$.  

A similar formula applies to the variance of a sum of random variables, but with an important additional condition, independence.   Informally two random variables are **independent** \index{independent random variables} if the outcome of one is not associated with outcomes of the other. When members of a large population are sampled randomly to participate in a survey, the survey responses are independent.  When study participants are assigned randomly to an intervention versus a control treatment, study outcomes are independent.

When two variables are not independent, they are not surprisingly called dependent.  Dependence is encountered more often than independence. People with larger shoe size tend to be taller than people with smaller feet, so shoe size and height are not independent.  People with lower income tend to rent rather than own a home, so income and home ownership are not independent.   

The concepts of independent random variables and correlated data are closely related. The numerical observations of independent random variables will be uncorrelated, while dependent random variables lead to correlated observations.

The mathematical definition for independent random variables uses the definition of independent events, but is not needed here.  For the purposes of this text it is sufficient to use the informal definition and insight into how variables are measured.

::: {.guidedpractice data-latex=""}

Which of the following pairs of measurements can be represented by independent random variables?  (a) Blood pressure and weight. (b) The response to a medication of two individuals who are not related and do not know each other. (c) Eye color and choosing to respond to an online survey. (d) Height of two siblings.  (e) Family income and zip code of residence. (f) Age and work status. [^random-variables-501]
:::

[^random-variables-501]: (b) and (c); there is no biological evidence that eye color is associated with are independent since there is no biological evidence these.  The others are dependent.



::: {.important data-latex=""}
**The variance of a sum of random variables.**

$$
\text{Var}(aX + bY) = a^2 \text{Var}(X) + b^2\text{Var}(Y).
$$ {#eq-variance-linear-combination-ind-rv}
This equation is valid only if the random variables are independent of each other. 

:::

For the sum $a + bZ$, the variance is $b^{2} \text{Var}(Z)$, since a constant $a$ has variance 0. When $b = 1$, variance of $a + Z$ is $\text{Var}(Z)$ - adding a constant to a random variable has no effect on the its variability.

::: {.workedexample data-latex=""}

The average body temperature in a healthy population measured in the Fahrenheit scale has been shown in some studies to be 97.9F, with a standard deviation of approximately 0.6F.  What are the average and standard deviation of body temperatures measured in the Celsius scale? 

------------------------------------------------------------------------

If $F$ and $C$ are random variables representing body temperature in Fahrenheit and Celsius scales, the conversion from $F$ to $C$ is
$$
  C = \frac{5}{9}F - 17.8
$$
Average temperature in Celsius is
$$
  E(C) = \frac{5}{9} E(F) - 17.8 = 0.556(97.9) - 17.8 = 36.6\text{ degrees celsius}
$$
The variance on the Celsius scale is
\begin{align*}
  \text{Var}(C) &= (\frac{5}{9})^2 \text{Var}(F) \\
                &= (0.309)(0.6)^2 \\
                &= 0.111
\end{align*}
The standard deviation on the Celsius scale is $\sqrt{0.111}$ = `r sqrt(0.111)`.

:::

Equations [-@eq-mean-linear-combination-rv] and [-@eq-variance-linear-combination-ind-rv] are illustrated in more detail in the next section.

```{r}
#| include: false
terms_chp_4 <- c(terms_chp_4, 
               c("expected value of sum of RVs",
                 "variance of sum of RVs",
                 "standard deviation of sum of RVs")
)
```


## Example: the cost of health insurance {#sec-cost-of-hmo-ins}

```{r hmo-visits-costs}

v_values <- c(0, 1, 2, 3, 4)
v_probs <- c(0.44, 0.19, 0.06, 0.06, 0.25)
s <- sum(v_probs)
v_mean <- sum(v_values * v_probs)
v_var <- sum((v_values - v_mean)^2 * v_probs)
v_sd <- sqrt(v_var)
c_values <- c(1200, 1220, 1240, 1260, 1280)
c_probs <- v_probs
c_mean <- 1200 + 20 * v_mean
c_var <- 3 * (20)^2 * v_var
c_sd <- sqrt(c_var)
```


In most  health insurance plans in the United States, members pay annually in three categories: a monthly premium, a deductible amount paid  each year before the insurance covers prescription drugs or hospitalization, and the ``out-of-pocket'' co-payments for each outpatient visit.   This example illustrates a hypothetical setting in which a Health Maintenance Organization uses its records to communicate the expected cost of the premium and outpatient visits to potential plan members who generally need only routine care.   It does not consider the cost of prescription drugs, specialized diagnostic tests or major events like hospitalization, and so does not include the deductible.

Since health care visits and expenses increase with age, the HMO decides to calculate this average among members age 25 - 40 who have not been diagnosed with a serious chronic disease, like diabetes or chronic heart disease.  After reviewing its records for the last several years, the HMO found that the majority of plan members in this segment had either no or one visit in an year, and none had more than 4 visits.  The plan analytics department used the data to create a probability distribution for annual visits of members in this population.

Suppose $V$ denotes the number of annual visits for a randomly chosen member of the plan age 25 - 40 with no serious chronic diseases.  @tbl-hmo-visit-dist shows the distribution of the number of annual visits, with $v_i$ representing the values of the random variable $V$.  

| $i$                     |   1    |    2    |    3    |    4    |   5    |
|:-----------------------:|:------:|:-------:|:-------:|:-------:|:------:|
| Number of visits, $v_i$ |   0    |    1   |    2    |    3    |   4     |
| $P(V = v_i)$            |`r v_probs[1]`|`r v_probs[2]`|`r v_probs[3]`|`r v_probs[4]`|`r v_probs[5]`|

: Distribution of HMO office visits. {#tbl-hmo-visit-dist}


::: {.guidedpractice data-latex=""}

Show that @tbl-hmo-visit-dist satisfies the conditions for a  probability distribution and describe the distribution in words to someone who has not studied probability. 
[^distributions-601]
:::

[^distributions-601]:@tbl-hmo-visit-dist satisfies the conditions of a discrete probability distribution: all probabilities are between 0 and 1, and the values sum to 1. `r v_probs[1] *100`% of this population never have a visit for outpatient care, while `r (v_probs[1] + v_probs[2]) * 100`% have 1 or fewer visits.  The least likely number of visits are 3 or 4 per year (`r v_probs[3]*100`% in each category), while a somewhat surprising number (`r v_probs[5]*100`% of members) have 4 visits per year. In this population plan members are either very healthy and never have an outpatient visit, or have a minor condition, such as allergy shots or physical therapy that causes them to book outpatient visits once a quarter. 

::: {.workedexample data-latex=""}

Construct a bar plot of the distribution of annual visits.  Describe the shape of the distribution using the terminology in @sec-intro-to-data used to describe distributions of data.

------------------------------------------------------------------------

@fig-bar-plot-hmo-visit-dist is a bar plot of this distribution.  The distribution is skewed right and has two prominent peaks at $V = 0$ and $V=4$, so is bimodal.  

```{r bar-plot-hmo-visit-dist}
#| label: fig-bar-plot-hmo-visit-dist
#| fig-cap: Bar plot of the distribution of the number of visits per year in a hypothetical HMO among healthy adults age 25 - 40.
#| fig-alt: |
#|   coming 
#| fig-width: 4

# Create the data frame
v_df <- tibble(v_values, v_probs)
ggplot(v_df, aes(x = factor(v_values), y = v_probs)) +
  geom_col(fill = IMSCOL["blue", "full"]) +
  scale_y_continuous(limits = c(0, 0.5), expand = c(0, 0)) +
  labs(
    x = "Annual visits",
    y = "Probabilities"
  ) 
```

:::

::: {.workedexample data-latex=""}

Calculate the mean and standard deviation for the number of visits.  Provide an interpretation of the mean. Is it a good summary measure for potential plan members?

------------------------------------------------------------------------

Using @eq-expectation-discrete-rv, the expected value of the annual number of visits is 
\begin{align*}
 E(V) &= (0)(0.44) + (1)(0.19) + \cdots + (4)(0.20)   \\
  &= `r round(v_mean,2)` \text{ visits per year}.
\end{align*}
Using @eq-variance-discrete-rv, the variance of $V$ is 
\begin{align*}
 \text{var}(V) &= (0 - `r v_mean`)^2 (0.44) + (1 - `r v_mean`)^2(0.19) + \cdots + (4 - `r v_mean`)^2 (0.25) \\
 &= `r round(v_var, 2)`.
\end{align*}
The standard deviation is $\sigma = \sqrt{\text{Var}(V)} = `r round(v_sd,2)`$ visits per year.

Since $E(V) = 1.49$, this population of plan members has (on average) approximately 1.5 outpatient visits per year.  From the shape of the distribution the mean is not a good summary measure for the distribution. More than half of the members (`r v_probs[1] + v_probs[2] * 100`%) have either 0 or 4 visits, and 1.5 is close to one of the least likely number of visits.
:::

::: {.workedexample data-latex=""}

Suppose now the monthly premium for the plan is \$100 and the co-payment for each office visit and standard services like physical therapy is \$20. (a) What can a new plan member matching the characteristics of this population expect to pay in the coming year? (b) If the annual premium and co-payment do not change for the next 3 years, what would be their expected their costs during that period?

------------------------------------------------------------------------

a. The total annual cost is a function of the premium and the co-payment.  If $C$ denotes annual outpatient costs,
$$
 C = (12)(100) + (20)(V).
$$
Using @eq-eq-mean-linear-combination-rv,
\begin{align*}
 E(C) &= E(1200 + (20)(V)) \\
      &= 1200 + (20)(E(V)) \\
      &= 1200 + (20)(`r v_mean`) \\
      &= `r round(1200 + 20 * v_mean, 2)` \text{ dollars }
\end{align*}
It would be statistically correct for the HMO to advertise that  a plan member in this population can expect to pay approximately \$`r round(1200 + 20 * v_mean, 0)` annually but it would be misleading because of the shape of the distribution.  Forty-four percent of patients pay only the premium (\$1200), while another 25% pay the cost of the premium + 4 visits (\$1280). The  plan should also remind members that these costs do not include the deductible for prescription drugs.

b. If $C_1, C_2$ and $C_3$ represent the cost of care for each of the three years,
\begin{align*}
E(C_1 + C_2 + C_3) &= E(C_1) + E(C_2) + E(C_3) \\
      &= (3)(E(C)) \\
      &= (3)(`r round(1200 + 20 * v_mean, 2)`) \\
      &= `r round(3 * (1200 + 20 * v_mean),2)` \text{ dollars}
\end{align*}

:::


::: {.workedexample data-latex=""}

Using the same assumptions of the above example, calculate the standard deviation of 3 years of costs for outpatient visits. Does it seem as though the standard deviation a reasonable measure of spread for this distribution?

------------------------------------------------------------------------

The variance for a single year of costs is $\text{Var}(C)$.  Using @eq-variance-linear-combination-ind-rv,
\begin{align*}
  \text{Var}(C) &= \text{Var}(1200 + (20)(V)) \\
                &= (20^2) \text{Var}(V) \\
                &= (400)(`r round(v_var, 2)`) \\
                &= `r round(c_var, 2)` \text{ dollars}^2.
  \end{align*}

Under the assumption that costs of each year are independent of those in previous years (a very strong assumption!), the variance for three years will be 

\begin{align*}
\text{Var}(C_1 + C_2 + C_3) &= \text{Var}(C_1) + \text{Var}(C_2) +\text{Var}(C_3) \\
                            &= (3)\text{Var(C)} \\
                            &= (3)(`r round(c_var,2)`) \\
                            &= `r 3 * round(c_var,2)` \text{ dollars }^2.
\end{align*}
The standard deviation is $\sqrt{`r 3* round(c_var,2)`} = \$`r round(sqrt(3* c_var), 2)`$.  It is not a good measure of spread, however, because of the bimodal nature of the distribution.

:::

::: {.guidedpractice data-latex=""}

Why is the assumption that the variances for the three years can be added such a strong (and perhaps untenable) assumption?
[^distributions-602]
:::

[^distributions-602]: The health characteristics of members of this population may not change from year to year, but they are unlikely to be independent: someone who has not visited the HMO for an outpatient visit is more likely not to visit in the next year, for instance, so the conditional probability of no visits in a coming year given that there were none in the previous year may be  different (and probably larger) than the unconditional probability of no visits.

The calculations for the mean and standard deviation of the annual cost of care did not use directly the distribution for annual cost, but instead used formulas for sums of variables.  The probability distribution for the annual cost of the premium plus co-pay for outpatient visits can be derived using the distribution of number of annual visits.  The expense to the plan member will be the \$1200 premium with probability 0.40 (the probability of no outpatient visits) when there are no visits, \$1220 with probability 0.10 when there is one visit, etc.  @fig-bar-plot-hmo-cost-dist is a bar plot for the distribution.

```{r bar-plot-hmo-cost-dist}
#| label: fig-bar-plot-hmo-cost-dist
#| fig-cap: Bar plot of the distribution of the annual costs per year in a hypothetical HMO among healthy adults age 25 - 40.
#| fig-alt: |
#|   coming 
#| fig-width: 4

# Create the data frame
v.df <- data.frame(
  v.values = c(1200, 1220, 1240, 1260, 1280),
  v.probs = c(0.40, 0.10, 0.05, 0.05, 0.40)
)

ggplot(v.df, aes(x = factor(v.values), y = v.probs)) +
  geom_col(fill = IMSCOL["blue", "full"]) +
  scale_y_continuous(limits = c(0, 0.5), expand = c(0, 0)) +
  labs(
    x = "Annual cost",
    y = "Probabilities"
  ) 
```


Because of the relationship between cost and the number of visits, Figures  [-@fig-bar-plot-hmo-visit-dist] and [-@fig-bar-plot-hmo-cost-dist] are similar: the bar heights showing probabilities are identical, and the number of visits have been replaced by the cost associated with each number of visits.  The distribution has the same right-skewed,  bimodal shape in both cases.

::: {.workedexample data-latex=""}

The median $m$ of a discrete random variable $X$ is the value that satisfies 
$$
P(X \leq m) \;\geq\; 0.5
\quad \text{and} \quad
P(X \geq m) \;\geq\; 0.5.
$$
Find the median annual cost for the premium and outpatient visits.  How does it compare to the expected cost?  

------------------------------------------------------------------------

The median is computed by finding the smallest value $m$ such that $P(X \leq m) \;\geq\; 0.5$.  For the random variable $C$ representing annual cost, that value is \$1220 since 
$$
P(C \leq 1200) = 0.40 < 0.50$$
while 
$$P(C \leq 1220) = 0.40 + 0.10 = 0.50 \geq 0.50
$$.

From the earlier example, the mean cost is $E(C)=$ \$1239.  Just as with distributions of data, the mean is larger than the median in this right-skewed distribution.  

:::

## Chapter review {#sec-chp4-review}


### Summary

Coming

### Terms


```{r}
#| label: tbl-terms-chp-4
#| tbl-cap: Terms introduced in this chapter.
#| tbl-pos: H
make_terms_table(terms_chp_4)
```

\clearpage

## Exercises {#sec-chp4-exercises}

Coming
