# Introduction to data {#sec-intro-to-data}

```{r load-background-files}
#| include: false
source("_common.R")
```

::: {.chapterintro data-latex=""}
Making observations and recording data are essential to empirical research and often begin a systematic approach to investigating scientific questions. The discipline of statistics focuses on addressing the following three questions: How should data be organized, summarized and explored? How can data best be collected? What can be learned from data?

This chapter provides an introduction methods for summarizing and exploring data.
:::

```{r start-collecting-terms}
#| include: false
terms_chp_1 <- c("data")

```

## Case study: Preventing peanut allergies {#sec-case-study-preventing-peanut-allergies}

\index{data!LEAP|(}

Is there an effective way to prevent peanut allergies in infants?

The proportion of young children in Western countries with peanut allergies has doubled in the last 10 years. Some studies have suggested that exposing infants to peanut-based foods, rather than excluding them from their diets, may help prevent peanut allergies (see @du2008early). The "Learning Early about Peanut Allergy" (LEAP, @du2015randomized) study was conducted in a controlled setting to investigate whether early exposure to peanut products reduces the likelihood of developing a peanut allergy.

The study team enrolled children in the United Kingdom between 2006 and 2009, selecting $640$ infants between $4$ and $11$ months old who had eczema, an egg allergy, or both. Each child was randomly assigned to one of two groups: the peanut consumption (treatment) group or the peanut avoidance (control) group. Children in the treatment group were fed at least 6 grams of peanut protein daily until 5 years of age, while children in the control group avoided peanut protein during the same period.

At age 5, each child underwent a peanut allergy test using an oral food challenge (OFC), which involved consuming 5 grams of peanut protein in a single dose. If a child showed no allergic reaction, the intervention (treatment or control) received by the child, the intervention they received was deemed a PASS; if the intervention failed to prevent an allergic reaction, the outcome was recorded as a FAIL. 

The primary analysis presented in the paper was based on data from $530$ children with a negative skin test at study entry. Although a total of $542$ children had an earlier negative skin test, data were unavailable for 12 children.

Individual-level data from the study are shown in @tbl-leap-study-results-df, which shows $6$ children in a dataset restricted to children with a negative skin prick test for a peanut allergy at the time of randomization. Each row represents a participant and shows the `participant.ID` (an anonymous participant identifier), `treatment.group` (the treatment randomly assigned) and `overall.V60.outcome` (result of the OFC at 60 months of age). The LEAP data can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

```{r leap-trimmed}
#| label:  tbl-leap-study-results-df
#| tbl-cap:  "Five patients from the LEAP study"
#| tbl-pos: H

LEAP_trimmed <- LEAP |>
  dplyr::select(
    participant.ID,
    treatment.group,
    overall.V60.outcome) |>
  slice(1:3, 529, 539)

LEAP_trimmed  |> 
  kbl(linesep = "", booktabs = TRUE, align = "lll")|>
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE)
```

The data can be organized in a two-way summary table; @tbl-leap-study-results shows the results grouped by treatment group and OFC outcome.

```{r leap-study-results}
#| label:  tbl-leap-study-results
#| tbl-cap:  "Results from the LEAP study"
#| tbl-pos: H
options(knitr.kable.NA = '')

LEAP_analyzed <- LEAP |> 
  dplyr::filter(stratum == "SPT-Negative") |> 
  dplyr::filter(!is.na(overall.V60.outcome))

LEAP_analyzed |> 
  count(overall.V60.outcome, treatment.group) |> 
  group_by(treatment.group) |> 
  pivot_wider(names_from = overall.V60.outcome, 
              values_from = n) |> 
  relocate(`FAIL OFC`, .after = `PASS OFC`) |>
  adorn_totals(where = c("row", "col"), name = "Sum") |> 
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped")
  )
```

The summary table makes it easy to identify patterns in the data. In the two groups combined, the intervention failed to prevent an allergy in $15.6\%$ of the children, but the proportions of failures in the two groups are different. In the avoidance group, the proportion of OFC failures was $36/263 = 0.137$ ($13.7\%$); in the consumption group, it was $5/267 = 0.019$ ($1.9\%$).

The difference in the proportions of OFC failures between the two groups is $11.8\%$; nearly $12\%$ more of the participants tested positive in the avoidance versus than consumption groups. The data can also be summarized by the ratio the two proportions ($0.137/0.019 = 7.31$); the rate of a subsequent allergy the avoidance group is more than $7$ times larger than in the consumption group; i.e., the risk of a subsequent peanut allergy was more than 7 times greater in the avoidance group relative to the consumption group.

Even without advanced statistical methods, the results of the LEAP study are striking. Early exposure to peanut products appears to be an effective strategy for reducing the likelihood of developing peanut allergies later in life. But are these results definitive? In other words, is the $11.8\%$ difference between the two groups larger than one would expect by chance variation alone? The statistical methods introduced in later chapters will provide the tools to answer this question.

In the language of medical research, LEAP was a \index{clinical trial} **clinical trial** -- a study done to improve the understanding of an intervention in a clinical setting. In statistical terms, LEAP was an \index{experiment} **experiment** involving human subjects -- a study done in a controlled setting to estimate the difference in outcome between two interventions. Experiments will be explored in more detail later in the text in @sec-experiments of @sec-collecting-data.

This study illustrates important issues in \index{evidence-based medicine} evidence-based medicine. At the time of the study, the prevailing approach to preventing peanut allergies in at-risk children was to avoid peanut products altogether. LEAP was pivotal in challenging this belief, providing evidence that avoidance, while intuitive, was not the most effective strategy.

Importantly, the study required informed consent from parents to allow their children to be randomly assigned to one of two interventions with uncertain outcomes. In return investigators were obligated to ensure that the study was justified by preliminary data, had a statistically sound design, and was conducted responsibly to protect the well-being of the participants.


\index{data!LEAP|)}

## Organizing and classifying data {#sec-data-organization}

### Observations, variables and data matrices {#sec-data-observations}

\index{data!crabs|(}

During spawning, a female horseshoe crab migrates to shore with a male attached to her spine to lay clusters of eggs in the sand. Additional male crabs, known as satellites, may join the pair and fertilize the eggs as well, potentially increasing genetic diversity of the offspring. 

The dataset `crabs` examined here contains observations on $173$ female crabs, with $5$ recorded measurements for each crab. The data originally appeared in Brockman [@brockmann1996satellite] and was used in *Categorical Data Analysis, 3rd ed.* [@agresti2013categorical]. It is available at Agresti's University of Florida web [`page`](https://users.stat.ufl.edu/~aa/cda/data.html). The dataset is used later in this chapter and in @sec-logistic-regression to explore the relationship between the features of a female crab and the number of satellites it attracts.^[See https://horseshoecrab.org/ for more information about these interesting creatures.]  The $5$ variables in the data are defined in @tbl-crabs-variable-descriptions.


| Variable Name | Variable description |
|:------------------------------|:----------------------------------------|
| color |  The color of the carapace (the shell carried by the crab on its back), with 4 values "light medium", "medium", "dark medium", "dark"|
| spine | The condition of the two spines along the edge of its abdomen, with 3 values "both good", "one worn or broken", "both worn or broken".|
| width |  The width of the carapace, in cm,  |
| satell | The number of male satellites the crab has attracted  |
| weight | The weight of the female, in kg. |

: Variable descriptions in the `crabs` data {#tbl-crabs-variable descriptions} {tbl-colwidths="\[25,75\]"}

It is important to check the definitions of variables, as they are not always clear. In the `crabs` data, the definitions specify that the measurements of `width` and `weight` are in metric units and the variable `spine` records the condition of the two spines near the abdomen of each crab.

@tbl-crabsDF shows data from $6$ randomly selected crabs from the $173$ observed in the study.   Each row represents a **case** (a single crab) and each column represents a recorded characteristic, called  a \index{variable} **variable**. The entries in a row are the values of the variables for that case, and the \index{distribution} **distribution** of a variable is its collection of values.  The distribution of the variable `weight`, for instance, is the set of values in the `weight` column.

A case is sometimes called a **unit of observation** or an \index{observational unit} **observational unit**. When observations are made on people participating in a study, as in LEAP, the observational units are called \index{human subjects} **human subjects** or \index{participants} **participants**. 

```{r load-crabs}
load("data/crabs.Rdata")
```

```{r crab-example-data}
#| label:  tbl-crabsDF
#| tbl-cap:  "Six observations from the crabs dataset"
#| tbl-pos: H
set.seed(080548) 
crabs  |> 
  sample_n(6) |>
  kbl(linesep = "", booktabs = TRUE, align = "llrr")|>
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE)

```

Because the observations are organized into rows and columns, the dataset is sometimes called a \index{data table} **data table** or a \term{data matrix} **data matrix**.  Data matrices are a convenient way to record and store data. If data are collected for another observational unit, a new row can easily be added.  Similarly, new column can be added for a new variable. 


Datasets are collected to learn about a larger \index{population} **population**. The `crabs` data were collected to learn about the features of female crabs that made them more attractive to males. The data were gathered in an observational study; the principles and interpretation of observational studies are discussed in @sec-observational-studies of @sec-collecting-data.

```{r}
terms_chp_1 <- c(terms_chp_1, "data matrix")
```

### Types of variables {#sec-data-variable-types}

A variable is classified based on the types of calculations that can be performed with it. The variables `width` and `weight` are \index{numerical variables} **numerical variables**, also called \index{quantitative variables} **quantitative variables**. Their values can be added, subtracted, or averaged. The two variables `width` and `weight` are \index{numerical variable!continuous} **continuous numerical variables** because they can take on any value within a specified range. The number of male satellites (`satell`) is a \index{numerical variable!discrete} **discrete numerical variable**, a variable that can take on one of a set of values, in this case an integer between 0 and the maximum number of satellites who can attach to a female horseshoe crab.

The variables `color` and `spine` are \index{categorical variables} **categorical variables**, also called \index{qualitative variables} **qualitative variables**. The values of categorical variables are names or labels; in this case the values are carapace colors or the condition of the spines of the crab. Arithmetic operations cannot be performed on categorical variables, but they can be tabulated. When the labels of a categorical variable have no natural ordering, such as `color`, it is a **nominal categorical variable**. `Spine` is an **ordered categorical variable** since its categories indicate worsening conditions of the spines. In R, categorical variables are also called \index{factor variable} **factor variables**.

\index{data!crabs|)}

```{r}
terms_chp_1 <- c(terms_chp_1, "numerical variable", "categorical variable")
```

Other types of variables arise in certain applications, often requiring specialized software to manipulate, and are not discussed in this text. Character or string variables are sometimes used to record an open ended responses to a question on a survey. Dates are often coded so that they can be manipulated with operations that extract the year or day of the week. Image data record the results of a photograph or other imaging procedure, such as a magnetic resonance imaging (MRI) scan of an organ or region of the body.

@fig-variable-types shows the types of variables used in this text.

```{r variable-type-figure}
#| label: fig-variable-types
#| out-width: 80%
#| fig-cap: Breakdown of variables into their respective types
#| fig-pos: H

knitr::include_graphics("images/variableTypes.png")

```

::: {.workedexample data-latex=""}
In addition to the treatment and outcome variables shown in @tbl-leap-study-results-df, the study team collected the `age` (in months) and `sex` of each participant and the results of the initial skin test for peanut allergies (negative or positive.) Classify `treatment.group`, `overall.V60.outcome` and these additional variables.

------------------------------------------------------------------------

The variables `treatment.group`, `overall.v60.outcome`, `sex` (male or female) and the result of the skin test all measure non-numerical quantities, and thus are categorical variables, each with two levels. `Age` is a continuous variable.
:::

::: {.guidedpractice data-latex=""}
Answers to guided practice problems are provided in the footnotes. Suppose that on a given day, a research assistant collected data on the first 20 individuals visiting a walk-in clinic: `age` (measured as less than 21, 21 - 65, and greater than 65 years of age), `gender`, `height`, `weight`, and `reason for the visit`. Classify each of the variables.[^intro-to-data-2]
:::

[^intro-to-data-2]: The variables `height` and `weight` are continuous numerical variables. `Age` as measured by the research assistant is ordinal categorical. `Sex` and the reason for the visit are nominal categorical variables.

## Summarizing and visualizing data {#sec-summarizing-visualizing-data}

### Categorical data {#sec-summarizing-categorical-data}

Categorical data are summarized in tables, such as @tbl-crabs-colors-frequency, which shows the number of crabs with each color.

```{r crabs-colors-freq-tbl}
#| label: tbl-crabs-colors-frequency
#| tbl-cap:  "Distribution of colors of the 173 crabs in the crabs dataset.  The Count column
#|    indicates the number of crabs with each of the colors."
#| tbl-pos: H
crabs |> 
  count(color) |>
  rename(Color = color) |> 
  rename(Count = n)  |> 
  adorn_totals(where = "row") |>
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE
  )
  

```

@tbl-crabs-colors-frequency is a \index{frequency table} **frequency table**; it shows that more females are color "medium" than any of the other three colors. When the proportion of crabs with each color is added to the table it is called a \index{relative frequency table} **relative frequency table**, as shown in @tbl-crabs-colors-relative-frequency. In fact, the majority ($54.9\%$) of females are color "medium".

```{r crabs-color-rel-freq-tbl}
#| label: tbl-crabs-colors-relative-frequency
#| tbl-cap:  "Distribution of colors of the 173 crabs in the crabs dataset"
#| tbl-pos: H

crabs |> 
  count(color) |>
  mutate("Proportion" = n/sum(n)) |>
  rename(Count = n) |>
  rename(Color = color) |> 
  adorn_totals(where = "row") |>
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE
  )
  
```

Frequency and relative frequency tables are typically used with nominal categorical variables, where the labels have no natural ordering. For ordered categorical variables, it is useful to include a column of cumulative proportions showing the fraction of cases up to and including each category in the natural ordering of the variable. 

@tbl-crabs-spine-cumulative-frequency shows the counts, proportions and cumulative proportions for the condition of the spines. Spine injuries are common in this group: only $21\%$ of the crabs have no worn or broken spines.  

```{r crabs-color-cum-freq-tbl}
#| label: tbl-crabs-spine-cumulative-frequency
#| tbl-cap:  "Counts, proportions and cumulative proportions of  spine condition 
#|     in the `crabs` dataset."
#| fig-alt: "Counts, proportions and cumulative proportions of spine condition
#|    in the `crabs` dataset."
#| tbl-pos: H
source("_common.R")


crabs |> 
  count(spine) |> 
  mutate(`Proportion` = n/sum(n)) |>
  mutate(`Cumulative proportion` = cumsum(`Proportion`)) |> 
  rename(Count = n) |> 
  rename(`Spine condition` = spine) |> 
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE
  )

```

\index{bar plot} The **bar plots** in @fig-crabs-counts-proportions provide a visual display of the data in @tbl-crabs-colors-relative-frequency. The plot on the left shows the numbers of crabs with each color; the right-hand side plot shows the proportions. Since proportions are the counts divided the total sample size, the two figures have the same shape; a bar plot with proportions is a re-scaled version of the bar plot with counts.

[Sections @sec-relationships-two-categorical] and [-@sec-relationships-one-numerical-one-categorical] explore how these and other features of female crabs are associated with the number of male satellites attracted during spawning.

```{r crabs-bar-graph}
#| label: fig-crabs-counts-proportions
#| fig-cap: Distribution of crab carapace colors.
#| fig-subcap:
#|   - Counts of color.
#|   - Proportions of color.
#| fig-alt: |
#|   Counts and proportions of the values of the color of the crabs.  Light medium
#|   is the most common color. 
#| fig-width: 4
#| layout-ncol: 2
ggplot(crabs, aes(x = color)) +
  geom_bar(fill = IMSCOL["blue", "full"]) +
  labs(x = "Carapace color", y = "Count")

crabs |>
  count(color) |>
  mutate(proportion = n / sum(n)) |>
  ggplot(aes(x = color, y = proportion)) +
  geom_col(fill = IMSCOL["blue", "full"]) +
  labs(x = "Carapace color", y = "Proportion")
```

### Numerical data {#sec-summarizing-numerical-data}

```{r portland-tree-fetch, include = FALSE}
library(pdxTrees)
set.seed(080546)

pdx <- get_pdxTrees_parks()
mu <- mean(pdx$Carbon_Storage_lb, na.rm = TRUE)
sigma <- round(sd(pdx$Carbon_Storage_lb, na.rm = TRUE),2)
portland_park_trees <- pdx  |> 
  dplyr::select(Common_Name, 
         Condition, 
         Tree_Height, 
         Structural_Value, 
         Carbon_Storage_lb, 
         Pollution_Removal_value,
         Carbon_Sequestration_value,
         Carbon_Sequestration_lb) |>  
  drop_na() |> 
  dplyr::slice_sample(n = 500) 

save(portland_park_trees, file = "./data/portland_park_trees.Rdata")
  
                
```

```{r}
load("./data/portland_park_trees.Rdata")
portland_size <- nrow(portland_park_trees)


```

During photosynthesis, trees remove carbon dioxide from the air, combine it with water, and convert it to sugars and oxygen. ^[The sugars created during photosynthesis are primarily sucrose, glucose and fructose.] The sugars are then distributed throughout the tree, and the carbon in them is stored in a process called carbon sequestration. Forests typically store twice as much carbon as they emit and are an important component in mitigating the effect of greenhouse gasses on climate change. How much carbon do trees store?


The [`Portland Tree Inventory project`](https://www.portland.gov/trees/get-involved/treeinventory) is a comprehensive inventory of trees in Portland, Oregon, compiled to help professionals and citizens protect and grow the urban Portland forest by showing the value of trees in the city. According to [`Portland’s city government`](https://www.portland.gov/council/documents/ordinance/passed/191975), trees provide an estimated $\$40$ an million annually in environmental benefits to Portland, including air pollution removal, avoided storm water runoff, and carbon sequestration. 

The inventory was compiled separately for trees in neighborhoods and parks and was completed in 2017.  It includes data on $25,534$ trees in Portland parks, with $34$ variables included for each case.  These variables include each tree's common and scientific names, the amount of carbon stored, the annual rate of carbon sequestration, and the financial value of the tree -- both as a landscape asset and as a tool for mitigating greenhouse gasses. This section uses some of variables from a random sample of $`r portland_size`$ trees. 

@tbl-portland-tree-descriptions shows the variable names and definitions. All but the first two variables are numerical variables.

| Variable Name | Variable description |
|:------------------------------|:----------------------------------------|
| Common_Name | Common name of the tree |
| Condition | A categorical variable with values Good, Fair, Poor, Dead |
| Tree_Height | Height from the ground to the live top of the tree, measured in feet. For dead trees, total height was measured. |
| Structural_Value | An estimate of the monetary value of replacing the tree and the benefits that it provides, based on methods from the Council of Tree and Landscape Appraisers |
| Carbon_Storage_lb | An estimate of the amount of carbon (in lbs.) that is bound up in both the above-ground and below-ground parts of the tree. It is total amount of carbon that is currently stored in the biomass of a tree. |
| Pollution_removal_value | An estimate of the monetary value associated with tree effects on atmospheric pollution annually. Expressed in US dollars and reflects the cost savings associated with the tree's role in improving air quality. |
| Carbon_Sequestration_lb | An estimate of the amount of carbon sequestered annually. |
| Carbon_Sequestration_value | Similar to Pollution_Removal_value, but an estimate of the financial value the annual carbon removal of the tree in terms of pollution mitigation. Expressed in US dollars. |

: Variable descriptions in the Portland tree data {#tbl-portland-tree-descriptions} {tbl-colwidths="\[25,75\]"}

```{r total-carbon, include = FALSE}
ds  <- portland_park_trees
carb_sum  <- round(sum(ds$Carbon_Storage_lb),0)
```
Some variables, such as `Carbon_Storage_lb`, cannot be measured directly and must be estimated from features of the tree that are observable, such as `Tree_Height` and `Condition`.  The Portland team used tools available in [`i Tree`](https://www.itreetools.org/) to estimate data that could not be observed directly.

<!-- chatgpt proofing to here, 13 Dec 2024 -->

The numerical variable `Carbon_Storage_lb` is an estimate of the amount of carbon stored in the tree. Collectively, the $500$ trees in this sample were storing approximately $`r carb_sum` \,\textrm{lbs}$ (more than $4,800$ tons!) of carbon at the date of the last inventory. How are these amounts of sequestered carbon distributed among the trees?

**Finding the center and spread of a distribution**

The distribution of a numerical variable is usually summarized by its center and spread. The \index{mean} **mean**, sometimes called the \indexthis{average}{mean!average} average, is a measure of center of a distribution and is denoted (generically) by $\overline{x}$. The average carbon storage in these trees is calculated by summing all the storage values and dividing by the total number of trees, as illustrated below.

```{r illus-sample-mean, include=FALSE}

# for illustrating sample mean median
# population mean mu and sd sigma calculated in code fetching data

x <- portland_park_trees$Carbon_Storage_lb
x1 <- x[1]
x2 <- x[2]
x3 <- x[3]
xl <- x[length(x)]
m <- round(mean(x),2)
M <- median(x)
l <- length(x)
sorted <- sort(x)
middle_low <- sorted[250]
middle_high <- sorted[251]

```

\begin{align*}
\overline{x} =& \frac{`r x1` + `r x2` + `r x3` \cdots + `r xl`}{`r l`} = `r m`\,\textrm{lbs}.
\end{align*}

Since data are usually a sample from a population, $\overline{x}$ is referred to as a \index{sample mean} **sample mean**. The \index{population mean} **population mean** of the larger population from which the sample was selected is denoted by the Greek letter $\mu$. In the tree data, $\mu$ is the average amount of carbon stored in all $25,534$ trees in the Portland parks. [^intro-to-data-4]

[^intro-to-data-4]: Population means almost never known because data on complete populations is rare. Since the tree inventory includes all trees in Portland parks, the mean $\mu$ of `Carbon_Storage_lb` can be calculated and is $`r m`$.

::: {.important data-latex=""}
**Mean.**

The mean of a variable is the sum of the observed values divided by the number of observations:

\vspace{-5mm}

$$ \bar{x} = \frac{x_1 + x_2 + \cdots + x_n}{n} $$
:::

The \index{median} **median** is another measure of center; it is the middle value of a distribution after the values have been ordered from smallest to largest. The median divides the distribution into two equal parts; half of the values are less than the median and half are greater. When there are an odd number of observations, the middle value is well-defined as the single middle value with the same number of observations below and above it. If the there are an even number of observations, the median is the average of the two middle observations. 

In the Portland tree data, there are $`r portland_size`$ trees.  When the After the carbon storage values have been sorted in ascending order, the median $`r M`$ is the average of the observations in rows $250$ and $251$, $`r middle_low`$ and $`r middle_high`$ respectively.

::: {.important data-latex=""}
**Median**

If the data are ordered from smallest to largest, the **median** is the middle observation. If there are an even number of observations, the median is the average of the two middle observations
:::

```{r calcs-for-deviation-example, include = FALSE}
#  code for simple calcs
#  for illustrating var and sd
d1 <- x1 - m
d2 <- x2 - m
d3 <- x3 - m
dl <- xl - m

# squared deviations
#
d1_sq <-  round(d1^2, 2)
d2_sq <-  round(d2^2, 2)
d3_sq <-  round(d3^2, 2)
dl_sq  <-  round(dl^2, 2)

sd_den = length(x) - 1

q <- round(sd(x), 2)
q2 <- round(var(x), 2)

```

The \index{standard deviation} **standard deviation** and \index{interquartile range} **interquartile range** are two common measures of spread.

The standard deviation describes the typical distance between an observation and the mean. The distance of an observation from the mean is its \index{deviation} **deviation**. The deviations for the $1^{st}$, $2^{nd}$, $3^{rd}$, and $500^{th}$ observations of carbon storage are: \begin{align*}
x_1-\overline{x} &= `r x1` - `r m` = `r x1 - m` \hspace{5mm}\text{ } \\
x_2-\overline{x} &= `r x2` - `r m` = `r x2 - m` \\
x_3-\overline{x} &= `r x3` - `r m` = `r x3 - m` \\
&\ \vdots \\
x_{500}-\overline{x} &= `r xl` - `r m` = `r xl - m`.
\end{align*}

The units for these $4$ values are lb$^2$.

The \index{variance} **variance** of a distribution (also called the **sample variance**) is the average of the squares of these deviations, and is denoted by $s^2$. For carbon storage,

\begin{align*}
s^2 &= \frac{`r d1`^2 + (`r d2`)^2 + (`r d3`)^2 + \cdots + (`r dl`)^2}{`r sd_den`} \\
&= `r q2`.
\end{align*}

The denominator of the variance is $n-1$ ($499$) rather than $n$ ($500$) for reasons that will be explained later. The units of the variance are the square of the units of the original measurements, in this case lb$^2$.

The \index{sample standard deviation} **sample standard deviation** $s$ is the square root of the variance: $$
s=\sqrt{`r q2`} = `r q` \,\textrm{lbs}.
$$

The \index{population standard deviation} **population standard deviation** of the population from which the sample was selected is denoted by the Greek letter $\sigma$. In this case $\sigma$ is the standard deviation of the distribution of carbon storage values for all $25,534$ trees in Portland parks. [^intro-to-data-5]

[^intro-to-data-5]: Calculated as $`r sigma`$ from the complete inventory.

::: {.important data-latex=""}
**Sample standard deviation.**

The sample standard deviation is the square root of the sum of the squared distances of each value from the mean divided by the number of observations minus one:

\vspace{-5mm}

$$
s = \sqrt{\frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}}
$$
:::


The \index{interquartile range} **interquartile range**, or \index{IQR} **IQR**, measures the spread of the middle $50%$ of the data. It is the distance between the third quartile ($Q_3$) and the first quartile ($Q_1$), expressed as $Q_3 - Q_1$.  The first quartile ($Q_1$), also known as the $25^{th}$ percentile, is the value below which $25%$ of the data fall. Similarly, the third quartile ($Q_3$), or the $75^{th}$ percentile, is the value below which $75%$ of the data fall.  The standard deviation has a similar interpretation as a measure of spread in symmetric distributions discussed later.

The first quartile ($Q_1$) is the median of the lower half of the data (below the overall median), while the third quartile ($Q_3$) is the median of the upper half of the data (above the overall median).  The overall median is sometimes referred to as $Q_2$, since it is the second quartile (the $50^{th}$ percentile). Together, $Q_1$, $Q_2$, and $Q_3$ divide the data into four equal chunks, each containing approximately $25%$ of the observations. 


::: {.important data-latex=""}
**Interquartile range (IQR).**

The interquartile range (IQR) is $Q_3 - Q_1,$ where $Q_1$ and $Q_3$ are the $25^{th}$ and $75^{th}$ percentiles of a distribution. It measures the spread of the central $50\%$ of a distribution.
:::

```{r, calc-90-quantile, include=FALSE}
q_9 <-  quantile(portland_park_trees$Carbon_Storage_lb, probs = 0.90)

```

An $\alpha$ **percentile**\index{percentile} is a number with $\alpha$% of the observations below it and $(100-\alpha)$% of the observations above it. For example, the $90^{th}$ percentile of `Carbon_Storage_lb` ($`r q_9`$) is larger than $90\%$ of the carbon values and smaller than $10\%$.

The \index{five number summary} **five number summary** is a compact numerical summary providing the largest and smallest observations, the first and third quartiles, and the median. @tbl-trees-five-num-summ-carbon shows the five number summary for `Carbon_Storage_lb`, with the mean added for good measure.

```{r five-num-summ}
#| label: tbl-trees-five-num-summ-carbon
#| tbl-cap: |
#|   The five number summary and the mean for carbon storage values in Portland tree data.
#| tbl-pos: H
summ_stat_portland_trees<- portland_park_trees |> 
  summarize(
    Minimum = min(Carbon_Storage_lb),
    `First Quartile (Q1)` = quantile(Carbon_Storage_lb, probs = 0.25),
    Median = median(Carbon_Storage_lb),
    Mean = mean(Carbon_Storage_lb),
    `Third Quartile (Q3)` = quantile(Carbon_Storage_lb, probs = 0.75),
    Maximum = max(Carbon_Storage_lb)
  ) 

summ_stat_portland_trees |> 
  mutate(across(where(is.numeric), ~ num(., digits = 1))) |> 
  kbl(linesep = "", 
      booktabs = TRUE, 
      align = "rrrrrr",
      digits = 2)  |>
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped")
  )

```

```{r describing-trees-five-num-summary, include=FALSE}
# values for text below
# 
cs_lb <- portland_park_trees$Carbon_Storage_lb
min_nr <- min(cs_lb)
min_r <- round(min_nr, 0)
max_r <- round(max(cs_lb), 0)
med <- median(cs_lb)
q1_r <- round(quantile(cs_lb, probs = 0.25), 0)
q3_r <- round(quantile(cs_lb, probs = 0.75), 0)
iqr_r <- q3_r - q1_r
m_r <- round(mean(cs_lb),1)

```

These trees store a large amount of carbon. The amount of carbon stored in each tree ranges from $`r min_nr`$ to approximately $`r max_r`$lbs. The median $`r med`$ lbs splits the data in half; $50\%$ of these trees store at least $1060$,lbs, Approximately $50\%$ of the observations are between the first and third quartiles, $`r q1_r`\,\textrm{lbs}$ and $`r q3_r`\,\textrm{lbs}$. The mean $`r m_r`$lbs is considerably larger than the median, and @fig-trees-carbon-beeswarm shows why.

The (aptly named) **beeswarm plot** \index{beeswarm plot} in @fig-trees-carbon-beeswarm shows an interesting (and extraordinary) feature of the distribution. In regions of the horizontal axis where the plot is wide (with many bees buzzing), there are large numbers of observations. The plot narrows as storage amounts increase and the number of observations decreases. There are many trees storing relatively smaller amounts of carbon (less than $2,000\,\textrm{lbs}$), but a few with very large amounts (larger than $4,000\,\textrm{lbs}$), some larger than $10,000\,\textrm{lbs}$. Averages are sensitive to extreme values at one end of a distribution as is easily be seen in the small dataset $2, 4, 6, 8, 10$, where the mean and median are both $6$. When the value $10$ is replaced by $40$, the mean increases to $12$. The large values in the right tail of the beeswarm plot explain the large value for the variance of `Carbon_Storage_lb`.

```{r beeswarm-carbon}
#| label: fig-trees-carbon-beeswarm
#| fig-cap: Beeswarm plot showing the distribution of carbon storage values in the Portland tree data
#| fig-alt: |
#|   Beeswarm showing the distribution of carbon storage values in the Portland tree data.  The large
#|        values 
#|   at the right edge of the plot cause the mean to be larger than the median.
#| fig-asp: 0.4

library(ggbeeswarm)
portland_park_trees |> 
  mutate(y = "  ") |> 
  ggplot(mapping=aes(x =  Carbon_Storage_lb, y = y)) + 
  geom_point(shape = 20, cex = .05) +
  geom_quasirandom(method = "pseudorandom", dodge.width = 0.05) +
  scale_x_continuous(
    breaks = seq(0, 16000, 2000))  +
  labs(x = "Carbon storage (lbs)", y = "") +
  theme(axis.ticks.y = element_blank())

```

```{r robust-example, include = FALSE}

x <- c(2, 4, 6, 8, 10)
mean(x)
x_sd <- sd(x)
y <- c(2,4,6,8,40)
y_m <- mean(y)
y_sd <- sd(y)

```

The median is a \index{robust statistic} **robust statistic** because unlike the mean it is minimally affected by a few extreme observations at one end of a distribution. For the same reason, the IQR is a robust measure of spread of a distribution, while the standard deviation is not. When $10$ is replaced by $40$ in the small dataset of 5 numbers, the standard deviation increases from $3.2$ to $15.8$, while the IQR ($8 - 4 = 4$) is unaffected.

The beeswarm plot shows that numerical summary statistics should be paired with visual displays whenever possible.

**Box plots and histograms**

\index{box plot} **Box plots** provide a visual display of the robust measures of the location and spread along with the values that might influence the less robust mean and standard deviation, and is constructed from a five number summary. @fig-trees-carbon-beeswarm-boxplot shows the beeswarm plot in @fig-trees-carbon-beeswarm and a box plot below it.

```{r values-for-boxplot}
# uses values calculated earlier
# 
lower_w <- q1_r - 1.5 * iqr_r
upper_w <- q3_r + 1.5 * iqr_r

```

In a box plot, the interquartile range is represented by a rectangle extending from the first to the third quartile, and the rectangle is split by the median (second quartile). The lines extending from first and third quartiles, commonly referred to as whiskers, reach toward $Q_1 - 1.5\times \textrm{IQR}$ and $Q_3 + 1.5\times \textrm{IQR}$. The whiskers always end at observed data points, so the calculated values define the maximum reach of the whiskers.

For `Carbon_Storage_lb`: 

- $Q_1 - 1.5 \times \textrm{IQR} = `r q1_r` - 1.5\times `r iqr_r` = `r lower_w`$ lbs. The lower whisker extends only to $0$ since there are no negative values of `Carbon_Storage_lb`. 

- The upper whisker potentially extends to $Q_3 + 1.5 \times \textrm{IQR} = `r q3_r` + 1.5\times `r iqr_r` = `r upper_w`$ lbs, but stops at $6487.5\,\textrm{lbs}$, the largest value less than $`r upper_w`\,\textrm{lbs}$.

Values beyond the whiskers are plotted with dots and labeled outliers. An \index{outlier} **outlier** is a value that is extreme relative to the rest of the data. There are many large outliers of `Carbon_Storage_lb`, as suggested earlier by the beeswarm plot @fig-trees-carbon-beeswarm.

The beeswarm and box plots in @fig-trees-carbon-beeswarm-boxplot provide different views of a distribution. The detail in the beeswarm shows how the observations of carbon storage values become less frequent as values of `Carbon_Storage_lb` increase. The box plot hides those details in favor of showing summarizing the center and spread of the data. The two graphs might be compared to the difference between reading a novel versus a skimming one page review.

*axes not perfectly aligned, but had trouble with patchwork*

```{r carbon-beeswarm-boxplot}
#| label: fig-trees-carbon-beeswarm-boxplot
#| fig-cap: Distribution of `Carbon_Storage_lb` from the Portland trees data.
#| fig-subcap:
#|   - Beeswarm plot
#|   - Box plot
#| fig-alt: |
#|   Two plots showing the same variable, carbon storage in lbs. The upper image is a 
#|   beeswarm plot, the lower is a box plot. 
#| fig-asp: 0.3
#| layout-ncol: 1

library(ggbeeswarm)
plot_df  <- portland_park_trees |> 
  mutate(y = "  ") 

ggplot(plot_df,
  mapping=aes(x =  Carbon_Storage_lb, y = y)) + 
  geom_point(shape = 20, cex = .05) +
  geom_quasirandom(method = "pseudorandom", dodge.width = 0.05) +
  scale_x_continuous(
    breaks = seq(0, 18000, 2000))  +
  labs(x = NULL, y = NULL) +
  theme(axis.ticks.y = element_blank()) 
  

ggplot(plot_df, 
  aes(x = Carbon_Storage_lb)) +
  geom_boxplot(outlier.size = 2.5) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  labs(x = "Carbon  Storage (lbs)") +
  scale_x_continuous(
    breaks = seq(0, 18000, 2000)
  ) 


```

A \index{histogram} **histogram** provides a balance between the detail of a beeswarm plot and the compact summary of a box plot. In a histogram, observations are grouped into bins and the height of a bar above each bin is the number of observations in the bin. @fig-trees-carbon-histogram is a histogram of the `Carbon_Storage_lb` distribution. The width of each bin is $2,000\, \textrm{lbs}$, and the bins correspond to the intervals $[0,2000), [2,000, 4,000), \ldots, [16,000, 18,000)$.^[The default interval for the histogram in R is open on the left, closed on the right, but the convention was reversed for this plot because of the possibility that some trees might not be storing any carbon.] The number of observations in each bin is shown at the top of the bars.

*count on leftmost bar not fully visible*

```{r trees-carbon-histogram}
#| label: fig-trees-carbon-histogram
#| fig-cap: |
#|   A histogram of `Carbon_Storage_lb` in the Portland trees data.  The histogram shows the
#|   few carbon storage values discussed earlier.
#| fig-alt: | 
#|   A histogram of `Carbon_Storage_lb` in the Portland trees data.  The histogram shows the
#|   few carbon storage values discussed earlier.
#|   
#| fig-asp: 0.4

ggplot(portland_park_trees, aes(x = Carbon_Storage_lb)) +
  geom_histogram(binwidth = 2000, closed = "left") +
  stat_bin(binwidth = 2000, aes(label = after_stat(count), y = after_stat(count)), geom = "text", vjust = -0.5) +
  labs(x = "Carbon storage (lbs)", y = "Count") +
  scale_x_continuous(
    breaks = seq(0, 18000, 2000)
  )

```

Histograms provide a view of the \index{data density} **data density**. Taller bars indicate more frequent observations, while shorter bars represent relatively rare observations. @fig-trees-carbon-histogram shows that most of trees store between $0$ and $4,000\,\textrm{lbs}$ of carbon, as was seen in @fig-trees-carbon-beeswarm, and fewer trees store more than $6,000$ lbs.

Histograms show the \index{shape} **shape** of a distribution\label{shapeFirstDiscussed}. The tails of a \index{symmetric distribution} **symmetric distribution** are approximately equal, with data trailing off from the center roughly equally in both directions. Asymmetry arises when one tail of the distribution is longer than the other, as in the histogram for carbon storage values. A distribution is said to be \termsub{right skewed}{skew!right skewed} when data trail off to the right, and \termsub{left skewed}{skew!left skewed} when data trail off to the left. @fig-trees-carbon-histogram shows a right skewed distribution.

The \index{mode} **mode** of a distribution is the location of its prominent peak. @fig-single-bi-multi-modal-plots} shows histograms that have one, two, or three major peaks. Such distributions are called \termsub{unimodal}{modality!unimodal}, \termsub{bimodal}{modality!bimodal}, and \termsub{multimodal}{modality!multimodal}, respectively. Any distribution with more than two prominent peaks is called multimodal. The less prominent peak in the unimodal distribution was not counted since it differs from its neighboring bins by only a few observations. Prominent is a subjective term, but it is usually clear in a histogram where the major peaks are.

```{r multi-modal-plots}
#| label: fig-single-bi-multi-modal-plots
#| fig-cap: |
#|   Counting only prominent peaks, the distributions are (left to right)
#|   unimodal, bimodal, and multimodal. The left plot is unimodal
#|   because only prominent peaks are counted.
#| fig-alt: |
#|   Three separate histograms on simulated data. The first histogram
#|   shows a unimodal distribution, the second a bimodal
#|   distribution, and a multimodal distribution.
#| fig-asp: 0.3
#| out-width: 95%

set.seed(080546)
df_modes <- tibble(
  uni   = rchisq(65, 6),
  bi    = c(rchisq(22, 5.8), rnorm(43, 16.5, 2)),
  multi = c(rchisq(20, 3), rnorm(30, 15, 1), rnorm(15, 25, 1.5))
)

p_uni <- ggplot(df_modes, aes(x = uni)) +
  geom_histogram(binwidth = 2) +
  labs(x = NULL, y = NULL) +
  ylim(0, 23) +
  xlim(0, 30)
p_bi <- ggplot(df_modes, aes(x = bi)) +
  geom_histogram(binwidth = 2) +
  labs(x = NULL, y = NULL) +
  ylim(0, 23) +
  xlim(0, 30)
p_multi <- ggplot(df_modes, aes(x = multi)) +
  geom_histogram(binwidth = 2) +
  labs(x = NULL, y = NULL) +
  ylim(0, 23) +
  xlim(0, 40)

p_uni + p_bi + p_multi
```

::: {.guidedpractice data-latex=""}
@fig-crabs-satell-histogram shows a histogram for the discrete numerical variable `satell` (number of male satellites) in the 173 females in the crab data. What are the important features of the variable shown in the histogram?[^intro-to-data-7]
:::

[^intro-to-data-7]: The distribution of `satell` has a mode at $0$; nearly half ($62$) of the $173$ females did not have any male satellites. The distribution is severely skewed right, indicating that while a large number of satellites is possible (as many as $15$), attracting more than $7$ is possible but rare. The shape of the histogram suggests that the median and IQR will be better measures of center and spread than the mean and standard deviation.

```{r crabs-satell-histogram}
#| label: fig-crabs-satell-histogram
#| fig-cap: |
#|   A histogram of the distribution number of male satellites in the crab data.
#| fig-alt: | 
#|   A histogram of the distribution number of male satellites in the crab data.
#|     Since the variable `satell` is a discrete numerical variable, the histogram
#|     is similar to a bar graph.
#|   
#| fig-asp: 0.4
ggplot(crabs, aes(x = satell)) +
  geom_histogram(binwidth = 1) +
  stat_bin(binwidth = 1, aes(label = after_stat(count)), geom = "text", vjust = -0.5) +
  labs(x = "Satellites", y = "Count") +
  scale_x_continuous( breaks = seq(0, 15, 1)) 
```

**The empirical rule for symmetric distributions**

The sample standard deviation has a direct interpretation as a measure of spread when a distribution is symmetric. The \index{empirical rule} **empirical rule** states that for symmetric, unimodal distributions, approximately $68\%$ of the observations are within one standard deviation of the mean, $95\%$ are within two standard deviations, and $99.7\%$ are within three standard deviations. The rule is based on the properties of bell-shaped distributions discussed in @sec-distributions, but it is a handy tool even without its theoretical basis.

```{r crab-width-summ-stat,  include = FALSE}
dc  <- crabs
summary(dc$width)
m_c  <- round(mean(dc$width), 1)
med_c  <- round(median(dc$width), 1)
sd_c  <- round(sd(dc$width), 1) 
int_1_lb  <- round(m_c - sd_c, 1)
int_1_ub  <- round(m_c + sd_c, 1)
int_2_lb  <- round(m_c - 2*sd_c, 1)
int_2_ub  <- round(m_c + 2*sd_c, 1)
int_3_lb  <- round(m_c - 3*sd_c, 1)
int_3_ub  <- round(m_c + 3*sd_c, 2)

```

@fig-crabs-width-histogram is a histogram of distribution of female crab widths. The distribution is approximately symmetric, with a slight right skewing; the mean $`r m_c`\,\textrm{cm}$ is only slightly larger than the median $`r med_c` \,\textrm{cm}$.

Applying the empirical rule, approximately $68\%$ of the female crabs should be between $`r  int_1_lb`$ and $`r int_1_ub`\,\textrm{cm}$ wide; $95\%$ should be between $`r  int_2_lb`$ and $`r int_2_ub`\,\textrm{cm}$ wide.

```{r crab-width}
#| label: fig-crabs-width-histogram
#| fig-cap: |
#|   A histogram of female crab `width` in the crabs data.  
#| fig-alt: | 
#|   A histogram of female crab `width` in the crabs data.  The distribution is slightly right-skewed but 
#|      approximately symmetric.
#|   
#| fig-asp: 0.4

ggplot(crabs, aes(x = width)) +
  geom_histogram(breaks = seq(20, 34, 1)) +
  labs(x = "Female crab width (cm)", y = "Count") +
  scale_x_continuous(
    breaks = seq(20, 34,2)
  )

```

**Transforming or re-expressing data**

The empirical rule does not apply to skewed distributions because the density of observations is different to the right and left of the mean. In many cases, a transformation or re-expressing of the data produces a symmetric distribution for the transformed data. The three transformations listed in @tbl-transforming-data are the ones most commonly used with skewed data

| Transformation | Recommended use |
|:--------------------------------|:--------------------------------------|
| $x^2$ | Unimodal, left-skewed distributions |
| $\sqrt{x}$ | Count data or data moderately skewed right |
| $\log_e{x}$ | More severely right skewed data. Data must have only positive values. Add a small constant to data with some zero values. |

: Transformations to try with skewed data {#tbl-transforming-data} {tbl-colwidths="[25,75]"}

In the Portland Tree Inventory, the Pollution Removal Value (`Pollution_Removal_value`) quantifies the annual economic benefits of a tree's capacity to remove air pollutants. It is typically expressed in monetary terms, reflecting the financial savings associated with the tree's role in improving air quality. The three histograms in @fig-trees-pollution-removal-histograms show the distributions of `Pollution_Removal_value` when (a) no transformation is applied and after square root (b) and logarithmic transformations. The square root transformation produces the more nearly symmetric distribution.

```{r trees-transformed-pollution-histograms}
#| label: fig-trees-pollution-removal-histograms
#| fig-cap: Three histograms of `Pollution_Removal_value`.
#| fig-subcap:
#|   - No transformation (US dollars)
#|   - Square root transformation.
#|   - Natural log transformation.
#| fig-alt: |
#|   Three histograms of `Pollution_Removal_value` after transformation. The square root transformation produces an approximately symmetric distribution
#| fig-width: 4
#| layout-ncol: 3

ggplot(portland_park_trees, aes(x = Pollution_Removal_value)) +
  geom_histogram(bins = 20)  +
  labs(x = "Pollution removal value (US dollars)", y = "Count") 

ggplot(portland_park_trees, aes(x = sqrt(Pollution_Removal_value))) +
  geom_histogram(bins = 20) +
  labs(x = "Square root of pollution removal value", y = "Count") 

ggplot(portland_park_trees, aes(x = log(Pollution_Removal_value + 0.1))) +
  geom_histogram(bins = 20) +
  labs(x = "Natural log pollution removal value", y = "Count") 

```

```{r sqrt-pollution-summary}
d <- portland_park_trees
root_pr <- sqrt(d$Pollution_Removal_value)
m_root_pr <- round(mean(root_pr), 2)
sd_root_pr <- round(sd(root_pr), 2)
sq_pr_lb  <- m_root_pr - sd_root_pr
sq_pr_lb  <- round(sq_pr_lb, 2)
sq_pr_ub  <- m_root_pr + sd_root_pr
sq_pr_ub  <- round(sq_pr_ub, 2)

```

::: {.workedexample data-latex=""}
The mean and standard deviation for the distribution of the square root of `Pollution_Removal_value are respectively $`r m_root_pr`$ and $`r sd_root_pr`$. Use the empirical rule to find the middle $68\%$ of the distribution.

------------------------------------------------------------------------

Suppose $x$ = `Pollution_Removal_value}`. The middle $68\%$ of the distribution of $y = \sqrt{x}$ is in the interval $\overline{y} \pm \textrm{std. dev.} y =`r m_root_pr` \pm `r sd_root_pr`$, or ($`r sq_pr_lb`$, $`r sq_pr_ub`$). Squaring the left and right endpoints, the middle $68\%$ of the distribution of $x$ will be in the interval ($`r sq_pr_lb^2`$, $`r sq_pr_ub^2`$).
:::

::: {.guidedpractice data-latex=""}
@fig-trees-height-trans-histograms shows histograms of `Tree_Height` in the original scale (a) and after square root (b) and log (c) transformations. Can the empirical rule be used with any of these three distributions? [^intro-to-data-8]
:::

[^intro-to-data-8]: No. On the original scale, the distribution is skewed right, and the distribution after a log transform is skewed left. The distribution after a square root transformation is symmetric, but it is not unimodal.

```{r trees-transformed-height-histograms}
#| label: fig-trees-height-trans-histograms
#| fig-cap: Three histograms of the `Tree_Height`.
#| fig-subcap:
#|   - No transformation (ft)
#|   - Square root transformation.
#|   - Natural log transformation.
#| fig-alt: |
#|   Three histograms of `Tree_Height` after transformation. The square root transformation produces an approximately symmetric distribution
#| fig-width: 4
#| layout-ncol: 3

ggplot(portland_park_trees, aes(x = Tree_Height)) +
  geom_histogram(bins = 20) +
  labs(x = "Tree Height (ft)", y = "Count") 

ggplot(portland_park_trees, aes(x = sqrt(Tree_Height))) +
  geom_histogram(bins = 20) +
  labs(x = "Square root of Tree Height", y = "Count") 


ggplot(portland_park_trees, aes(x = log(Tree_Height))) +
  geom_histogram(bins = 20) +
  labs(x = "Natural log of Tree Height", y = "Count") 

```

## Relationships in data {#sec-relationships-in-data}

Relationships in data exist when a variable, called \index{explanatory variable} **explanatory variable** has potentially useful information about the distribution (i.e., the possible values) of another variable, called a \index{response variable} **response variable**. Do the values of response increase as the values explanatory variable increase? Do the values of the response tend to differ by the levels of the explanatory variable? In LEAP the explanatory variable is the intervention and the OFC outcome the response. @tbl-leap-study-results showed that the distribution of the response changed with the levels of the intervention; the proportion of OFC failures in the peanut avoidance group was substantially larger than in the consumption group. A relationship is also called an \index{association} **association**. In LEAP there was an association between the intervention and outcome.

Exploring relationships in data is a major goal of statistics, and, indeed, of research in general. Much of this text explores methods for studying relationships, including numerical and graphical methods to display relationships and the use of statistical models such as regression. This section illustrates numerical and graphical methods for simple relationships between two variables, beginning with two categorical variables. [Chapters @sec-simple-linear-regression], [-@sec-multiple-linear-regression] and [-@sec-logistic-regression] discuss regression models to explore relationships among two or more variables.

### Two categorical variables {#sec-relationships-two-categorical}

**Contingency tables**

```{r missing-count-wvs}

load("./data/wvs_edu_health.Rdata")
load("./data/wvs_edu_health_cc.Rdata")

n_original <- nrow(wvs_edu_health)
n_dropped <- nrow(wvs_edu_health) - nrow(wvs_edu_health_cc)
n_vars <- ncol(wvs_edu_health)
n_cases <- nrow(wvs_edu_health_cc)
```

Studying a relationship begins with a question. This section uses the World Values Survey to explore whether health status varies with education.

The [`World Values Survey`](https://www.worldvaluessurvey.org/WVSContents.jsp) (WVS) explores values, beliefs, and cultural norms across $100$ countries representing $90\%$ of the world's population. A national team in each country is responsible for collecting a representative sample of all individuals between the ages 18 and 85 years, inclusive, with a minimum sample size of 1,200 respondents. Interviews are conducted in person, online or by phone, depending on the resources available in each country. The WVS began in 1981 and is conducted in waves; [`Wave 7`](https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp), the most recently conducted wave, was completed in 2022.

This section explores responses to education and health assessment questions from Wave 7 respondents from $9$ selected countries, using a dataset with $`r n_vars`$ variables and $`r n_cases`$ cases. @tbl-wvs-var-descriptions shows the countries in the data used here and the coding for responses to the education and health status questions, and @tbl-wvs-9-countries shows number of respondents from each country.

| Variable | Description |
|:-----------------------------------------|:-----------------------------|
| country | Nine countries coded with standard abbreviations: ARG, BRA, CAN, CHN, DEU, EGY, ETH, JPN, KEN, NZL, USA |
| Education_level | Ordered categorical variable grouping responses to a question asking highest level attained by the respondent: Lower, no education to lower secondary education; Middle, upper secondary education to short term training designed to prepare someone for the workforce; High, Bachelor degree or higher |
| Health_status | Ordered categorical variable with self reported current health status: Very Poor, Poor, Fair, Good, Very Good |

: Variables used from the WVS data. {#tbl-wvs-var-descriptions} {tbl-colwidths="\[25,75\]"}

*plot does  not center, at least in html*


```{r 9-country-table}
#| label: tbl-wvs-9-countries
#| tbl-cap:  "The number of cases in each of the 9 countries from the WVS data"
#| tbl-pos: H
wvs_edu_health_cc |> 
  count(Country) |> 
  rename(Count = n)  |> 
  adorn_totals(where = "row") |>
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE,
    position = "center")  |> 
    scroll_box(width = "50%")
```

For simplicity, this brief analysis skips two typically performed when preparing a survey for analysis. Because some people sampled do not respond to a survey, the respondents are usually not a completely representative sample from a country's population. The WVS data includes weights for each respondent that can be used to create a further sub-sample that matches the population demographics of each country. That has not been done with these data. In addition, respondents who participate in a survey always have the option not to provide a response. Instead of exploring the reasons for non-response to questions, this analysis is restricted to participants who chose to respond. A small number of respondents ($`r n_dropped`$) of the $`r n_original`$ respondents in the original sample chose not to respond to at least one of the questions used here.

```{r wvs-table-elements, echo = FALSE}
df <- wvs_edu_health_cc

t <- table(df$Education_level, df$Health_status)
t_tot <-  addmargins(table(df$Education_level, df$Health_status))
t_rprop <- round(proportions(t, 1), 3)
t_cprop <- round(proportions(t, 2), 3)

```

@tbl-wvs-edu-health is a **contingency table** \index{contingency table} showing the number responses to the questions of attained educational level and perceived health status. A contingency table summarizes data for two categorical variables.[^intro-to-data-9] The rows of @tbl-wvs-edu-health correspond to levels of education and the columns to health status. The cells of the table contain the counts for each row and column combination. For instance, $`r t_tot["Middle", "Fair"]`$ respondents reported a `Middle` level of education (at most a secondary school or specific job training) and `Fair` health status.

[^intro-to-data-9]: A contingency table is also called a two-way table, and the data in the table are often called cross-classified data.

Contingency tables are characterized by the number of rows and columns corresponding to the levels of the two variables. @tbl-wvs-edu-health is a $3 \times 5$ table, with totals added for convenience. The \index{row totals} **row totals** in the column labeled `Sum` provide the total counts for each row, and the \index{column totals} **column totals** in the row labeled `Sum` are totals for each column. Collectively, these are referred to as the \index{marginal totals} **marginal totals**. Among the $`r n_cases`$ respondents, $`r t_tot["Middle","Sum"]`$ reported `Middle` education. The entry in the lower right corner is called the \index{grand total} **grand total**.


```{r wvs-edu-health-tbl}
#| label: tbl-wvs-edu-health
#| tbl-cap:  "Health rating by educational level"
#| tbl-pos: H

wvs_edu_health_cc |> 
  count(Health_status, Education_level) |> 
  group_by(Education_level) |> 
  pivot_wider(names_from = Health_status, 
              values_from = n) |> 
  adorn_totals(where = c("row", "col"), name = "Sum") |> 
  kbl(linesep = "", booktabs = TRUE) |> 
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE) |>
  add_header_above(c(" " = 1, "Health_status" = 5, " " = 1)) |>
  column_spec(1, width = "8em") |>
  column_spec(2:7, width = "4em")
```

What else does the table tell us about the $`r t_tot["Sum", "Sum"]`$ participants responding to the survey? A large majority of the participants ($`r t_tot["Sum", "Good"]`$ + $`r t_tot["Sum", "Very Good"]`$ = $`r t_tot["Sum", "Good"] + t_tot["Sum", "Very Good"]`$) responded that their health was `Good` to `Very Good`. A small number of respondents ($`r t_tot["Sum", "Very Poor"]`$) reported `Very Poor` health status. This is a generally healthy population.

::: {.workedexample data-latex=""}
Very few of the respondents reported `Very Poor` health status. It may be the case that participants in very poor health did not respond to this question. Comment on whether this may have lead to a substantial under-estimate of the frequency of participants in very poor health.

------------------------------------------------------------------------

$`r n_dropped`$ of the $`r n_original`$ participants in the original sample chose not to respond to at least one of the questions about education or health status. If all of those non-responders were in very poor health, the number with very poor health would not be larger than $`r t_tot["Sum", "Very Poor"]`$ + $`r n_dropped`$ = $`r t_tot["Sum", "Very Poor"] +  n_dropped`$ . The proportion of participants with very poor health is no larger than $`r (t_tot["Sum", "Very Poor"] +  n_dropped) / t_tot["Sum", "Sum"]`$, more than double the proportion in @tbl-wvs-edu-health ($`r t_tot["Sum", "Very Poor"] / t_tot["Sum", "Sum"]`$). Under these assumptions @tbl-wvs-edu-health may well provide an under estimate of relative frequency of participants in very poor health.[^intro-to-data-10]
:::

[^intro-to-data-10]: @sec-sample-surveys discusses sources of bias in surveys in more detail.

```{=html}
<!-- guided practice about educational background 

The proportion with a secondary school education  or less $(5136 + 9194)/19796 = 0.724$, or $74.2\%$.

-->
```

Is `Educational_status` a useful explanatory variable for `Health_status`?  Does knowing someone’s educational level provide meaningful information when predicting their health status?

In @tbl-wvs-edu-health-row-prop, the counts in @tbl-wvs-edu-health have been replaced by \index{row proportion} **row proportions**, which represent the \index{conditional distribution} **conditional distribution** of `Health_status` for each level of `Education_level`. These proportions show how health status is distributed within each educational level.

For example, of the $`r t_tot["Middle", "Sum"]`$ respondents with a `Middle` level of education, $`r t_tot["Middle", "Good"]`$ had `Good` health status, corresponding to a  proportion of $`r t_tot["Middle", "Good"] / t_tot["Middle", "Sum"]`$. Forty-six percent of the respondents among those with a secondary school education consider their health status good. The row proportions sum to 1 since everyone within each `Educational_level` is in one (and only one) of the `Health_status` categories.

```{r wvs-edu-health-row-proportion}
#| label: tbl-wvs-edu-health-row-prop
#| tbl-cap:  "Health rating by educational level, with row proportions"
#| tbl-pos: H
wvs_edu_health_cc |>
 count(Health_status, Education_level) |> 
 group_by(Education_level) |> 
 mutate(proportion = n / sum(n)) |>
 dplyr::select(-n)  |> 
 pivot_wider(names_from = Health_status, 
              values_from = proportion) |> 
 adorn_totals(where = "col") |> 
 kbl(linesep = "", booktabs = TRUE, digits = 3) |> 
 kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE) |>
 add_header_above(c(" " = 1, "Health_status" = 5, " " = 1)) |>
 column_spec(1, width = "8em") |>
 column_spec(2:7, width = "4em")  

```

::: {.guidedpractice data-latex=""}
Among the respondents with a bachelor's degree or higher, what proportion reported `Poor` health status? What proportion reported `Poor` or lower health status?[^intro-to-data-11]
:::

[^intro-to-data-11]: The relevant proportion reporting `Poor` health in @tbl-wvs-edu-health-row-prop in the row `High` and the column `Poor`, is $`r t_rprop["High", "Poor"]`$. The proportion reporting `Poor` or lower health status is $`r t_rprop["High", "Poor"]` + `r t_rprop["High", "Very Poor"]` = `r t_rprop["High", "Poor"] + t_rprop["High", "Very Poor"]`$.

The row proportions in @tbl-wvs-edu-health-row-prop show small differences across the rows but are reasonably consistent. For example, across the three education levels, the least frequent health status was `Very Poor`, while the most frequent was `Good`. At each level of education, the proportion reporting `Poor` health status is less than $10\%$; the proportion reporting `Fair` health status falls within the range $20 - 30\%$. `Educational_level` does not appear to be a useful explanatory variable for `Health_status` since its distribution does not change much across the levels of `Educational_level`.

Bar plots can be modified to show graphically relationship in contingency tables. @fig-wvs-edu-health-barplot shows three bar plots with `Educational_level` as an explanatory variable for the response `Health_status`.    

- @fig-wvs-edu-health-barplot(a) is a \index{frequency bar plot} **frequency bar plot** showing the number of observations for the health status responses within each value of `Education_level`. The plot is also called a \index{stacked bar plot} **stacked bar plot** or \index{segmented bar plot} **segmented bar plot**  and represents the data in @tbl-wvs-edu-health. It shows the total number of observations for each level of education, but does not make it easy to the proportions or the precise number of responses for each `Health_status` category.

- @fig-wvs-edu-health-barplot(b) is a \index{relative frequency bar plot} relative frequency bar plot, illustrating the row proportions from @tbl-wvs-edu-health-row-prop. It displays the proportions of responses within each educational level, making it useful for comparing  distributions. However, it obscures the sample sizes, which are important for understanding the size of the dataset.

- @fig-wvs-edu-health-barplot(c) is a \index{dodged bar plot} dodged bar plot, where separate bars for each health status category are displayed for each Educational_level. This plot also reflects the data in @tbl-wvs-edu-health, but makes it easier to identify of the number of responses for each `Health_status` category within each educational level. However, it also does not show the proportions that indicate the distribution of health status within educational level.

 In the WVS data, all three plots in @fig-wvs-edu-health-barplot are consistent with the observation that the distribution of `Health_status` varies little with `Educational_level`.

*fix palette*


```{r wvs-edu-health-barplot}
#| label: fig-wvs-edu-health-barplot
#| fig-cap: Three bar plots showing the relationship between educational level and health, WVS data.
#| fig-subcap:
#|   - frequency bar plot
#|   - relative frequency bar plot
#|   - Dodged bar plot
#| fig-alt: | 
#|   Three bar plots showing the relationship between educational level and health, WVS data.
#|   Both variables are self-reported
#| fig-width: 4.0
#| layout: [[50, 50], [-20, 60, -20]]

ggplot(wvs_edu_health_cc, aes(x = Education_level, fill = Health_status)) +
  geom_bar(show.legend = FALSE) +
  labs(x = "Educational level",
       y = "Count",
       fill = "Health_status") 

ggplot(wvs_edu_health_cc, aes(x = Education_level, fill = Health_status)) +
  geom_bar(position = "fill", show.legend = FALSE) +
  labs(x = "Educational level",
       y = "Proportion",
       fill = "Health_status") 

ggplot(wvs_edu_health_cc, aes(x = Education_level, fill = Health_status)) +
  geom_bar(position = "dodge") +
  labs(x = "Educational level",
       y = "Count",
       fill = "Health_status") +
  theme(legend.position = "bottom")

```

Column proportions can also replace counts in a contingency table. In @tbl-wvs-edu-health-col-prop counts have been replaced by column proportions. The columns show the conditional distributions of educational level for each reported health status. Among the respondents reporting `Very Good` for `Health_status`, $28.9\%$ had a bachelor's degree or higher. In this table, `Health_status` serves as the explanatory variable for the response `Educational_level`.

```{r wvs-edu-health-col-proportion}
#| label: tbl-wvs-edu-health-col-prop
#| tbl-cap:  "Health rating by educational level, with column proportions"
#| tbl-pos: H
wvs_edu_health_cc |>
 count(Health_status, Education_level) |> 
 group_by(Health_status) |> 
 mutate(proportion = n / sum(n)) |>
 dplyr::select(-n)  |> 
 pivot_wider(names_from = Health_status, 
              values_from = proportion) |> 
 adorn_totals(where = "row") |> 
 kbl(linesep = "", booktabs = TRUE, digits = 3) |> 
 kable_styling(
    bootstrap_options = c("striped", "condensed"),
    latex_options = c("striped"),
    full_width = FALSE) |>
 add_header_above(c(" " = 1, "Health_status" = 4, " " = 1)) |>
 column_spec(1, width = "8em") |>
 column_spec(2:6, width = "4em")  

```

::: {.workedexample data-latex=""}
In these data, would `Health_status` be a reasonable explanatory variable for `Education_level`?

------------------------------------------------------------------------

No. `Health_status` is reflects perceived health at the time of the interview, while `Educational_level` refers to something in the past.
:::

::: {.guidedpractice data-latex=""}
What does the number $`r t_cprop["Lower", "Poor"]`$ represent in the table?[^intro-to-data-12]
:::

[^intro-to-data-12]: Among the participants with 'Poor' health status $`r t_cprop["Lower", "Poor"] * 100`$% have less than a secondary school education.

::: {.guidedpractice data-latex=""}
Among the participants reporting `Fair` health status, what proportion have a secondary or higher education? [^intro-to-data-13]
:::

[^intro-to-data-13]: $`r t_cprop["Middle", "Fair"]`$ + $`r t_cprop["High", "Fair"]`$ = $`r t_cprop["Middle", "Fair"] + t_cprop["High", "Fair"]`$, or almost $70\%$.


**Two-by-two tables: relative risk**

The results from medical and public health studies are often presented in \index{two-by-two tables} **2 $\times$ 2 tables**, contingency tables for categorical variables that have two levels. For example, do children living in areas with high concentrations of air pollution tend to develop asthma? In a typical $2 \times 2$ table, the rows define two groups of participants (e.g., exposed to air pollution versus not), while the columns represents the two possible outcomes (e.g., developed asthma versus not).^[Since a $2 \times 2$ table is symmetric, the roles of rows and columns can be reversed, but it is customary to use rows for the explanatory variable and columns for the response, convention is followed here.]  


@tbl-gen-2x2-table shows the general form of a $2 \times 2$ table.

|     | Outcome A | Outcome B | Sum              |
|---------:|-----------:|-----------:|--------------:|
| **Group 1**   | $a$         | $b$         | $a + b$            |
| **Group 2**   | $c$         | $d$         | $c + d$            |
| **Sum**     | $a +c$      | $b+d$       | $a + b + c+ d = n$ |

: The general form of a $2 \times 2$ table {#tbl-gen-2x2-table} 

@tbl-leap-study-results showing the results of LEAP in @sec-case-study-preventing-peanut-allergies has this form. 


Because of the simple structure of $2 \times 2$ tables, it is possible to calculate single number summaries of the strength of a relationship or association. In LEAP, the proportion of OFC failures in the avoidance group was $36/263 = 0.137$; in the consumption group, it was $5/267 = 0.019$. These two proportions are a measure of the risk of a peanut allergy in each group. The ratio of the proportions ($0.137/0.019 = 7.31$) indicates that the risk of peanut allergy in the avoidance group is more than $7$ times as large as that in the consumption group. The \index{relative risk} **relative risk** of an allergy, comparing the avoidance to the consumption group, is $7.31$.  In statistical notation

\begin{align*}
RR_{\textrm{failing OFC}} &= \dfrac{\textrm{proportion in avoidance group who failed OFC}}{\textrm{proportion in consumption group who failed OFC}} \\
    &= \dfrac{36/263}{5/267} \\ 
    &= 7.31. 
\end{align*}


In most studies a relative risk of 1.5 or larger is considered important, so the relationship between intervention and outcome in LEAP is a strong one.  Relative risk summarizes both the strength of a relationship (how much it differs from $1$) and and its direction (whether is is larger or smaller than $1$).


::: {.workedexample data-latex=""} 
A study is conducted to assess the association between smoking and cardiovascular disease (CVD), in which researchers identified a cohort of individuals and categorized them according to smoking and disease status. If the relative risk of CVD is calculated as the ratio of the proportion of smokers with CVD to the proportion of non-smokers with CVD, interpret the results of the study if the relative risk equals 1, is less than 1, or greater than 1.

--------------------------------------------------------------

A relative risk of 1 indicates that the risk of CVD is equal for smokers and non-smokers.

A relative risk less than 1 indicates that smokers are at a lower risk of CVD than non-smokers; i.e., the proportion of individuals with CVD among smokers is lower than the proportion among non-smokers.
  
A relative risk greater than 1 indicates that smokers are at a higher risk of CVD than non-smokers; i.e., the proportion of individuals with CVD among smokers is higher than the proportion among non-smokers.
:::

::: {.guidedpractice data-latex=""}
For the study described above, suppose that of the 231 individuals, 111 are smokers. 40 smokers and 32 non-smokers have cardiovascular disease. Calculate and interpret the relative risk of CVD.[^intro-to-data-14]
:::

[^intro-to-data-14]: The relative risk of CVD, comparing smokers to non-smokers, is $(40/111)/(32/120) = 1.35$. Smoking is associated with a 35\% increase in the probability of CVD; in other words, the risk of CVD is 35\% greater in smokers compared to non-smokers.

Relative risk relies on the assumption that the observed proportions of an event occurring in each group are representative of the risk, or incidence, of the event  within the populations from which the groups are sampled. For example, in the LEAP data, the relative risk assumes that the proportions $33/263$ and $5/267$ are estimates of the proportions OFC failures in the larger populations of infants who would avoid or consume peanut products, respectively. 

::: {.workedexample data-latex=""} 

Suppose another study to examine the association between smoking and cardiovascular disease is conducted, but researchers use a different study design than described above. In this new study, 90 individuals with CVD and 110 individuals without CVD are recruited. Among those with CVD, 40 are smokers, while among those without CVD, 80 are non-smokers. Should relative risk be used to summarize the observations from the new study?

-------------------------------------------------------

Relative risk should not be calculated for these observations. Since the number of individuals with and without CVD is fixed by the study design, the proportion of individuals with CVD within a certain group (smokers or non-smokers) as calculated from the data is not a measure of CVD risk for that population.

:::

::: {.guidedpractice data-latex=""}

For a study examining the association between tea consumption and esophageal carcinoma, researchers recruited 300 patients with carcinoma and 571 without carcinoma and administered a questionnaire about tea drinking habits (see @islami2009tea). Of the 47 individuals who reported regularly drinking green tea, 17 had carcinoma. Of the 824 individuals who reported never or very rarely drinking green tea, 283 had carcinoma. Evaluate whether the proportions $17/47$ and $283/824$ are representative of the incidence rate of carcinoma among individuals who regularly drink green tea and those who do not.[^intro-to-data-15]

:::

[^intro-to-data-15]: The proportions calculated from the study data should not be used as estimates of the incidence rate of esophageal carcinoma among individuals who drink green tea regularly and those who do not, since the study selected participants based on carcinoma status.


::: {.important data-latex=""}
**Relative Risk**
The relative risk (RR) of Outcome A in @tbl-gen-2x2-table can be calculated using either Group 1 or Group 2 as the reference group:   

$$
		RR_{\textrm{A, comparing Group 1 to Group 2}} = \dfrac{a/(a+b)}{c/(c+d)}
$$
		
$$
RR_{\textrm{A, comparing Group 2 to Group 1}} = \dfrac{c/(c+d)}{a/(a+b)}
$$

Let $RR = RR_{\textrm{A, comparing Group 1 to Group 2}}$.   

- If $RR > 1$ Group 1 members are more at risk for Outcome A than members Group 2.  

- If $RR = 1$ the risk for Outcome A in the two groups is equal.    

- If $RR < 1$ Group 1 members are less at risk for Outcome A than members of Group 2.

Relative risk should only be calculated for data where the proportions $a/(a+b)$ and $c/(c+d)$ represent the incidence of Outcome A within the populations from which Groups 1 and 2 are sampled.
:::

*should we add OR?*

### One numerical and one categorical variable {#sec-relationships-one-numerical-one-categorical}

Methods for comparing numerical data across groups use \index{side-by-side box plots} **side-by-side box plots** or \index{stacked box plots} **stacked box plots** for exploring the distribution of a numerical variable across category.

*reorder factors in original construction*


```{r}
#| label: fig-trees-condition-carbon-boxplot
#| fig-cap: |
#|   Side-by-side box plots of the distribution carbon storage by tree condition.
#| fig-alt: | 
#|   Side-by-side box plots of the distribution carbon storage by tree condition.  The box 
#|   plots are ordered from top to bottom in ascending order of the median of stored carbon
#    in each group.  Surprisingly, even dead trees are storing carbon.
#|   
#| fig-asp: 0.4

ggplot(portland_park_trees, aes(
  y = Carbon_Storage_lb, 
  x = reorder(Condition, -Carbon_Storage_lb))) +
  geom_boxplot() +
  scale_color_openintro("two") +
  labs(y = "Carbon storage (lbs)", x = "Tree condition") +
  scale_y_continuous(
    breaks = seq(0, 16000, 4000))
```

*text does not match figures.  look at cowplot and plot_gridto ref subplots*

@fig-crabs-color-spine-stacked-satell-boxplot uses  The median number of satellites is larger than 4 for `light medium` females, while the at least $50\%$ of the dark females have no satellites, since the median is $0$.   The relationship between number of satellites shows no evident pattern.  Females with one worn or broken spine have fewer satellites that either of the other two categories. 


```{r crabs-color-spine-stacked-box}
#| label: fig-crabs-color-spine-stacked-satell-boxplot
#| fig-cap: |
#|   Two stacked box plots of the distribution number of male satellites by color and by spine condition.
#| 
#| fig-alt: | 
#|   The median number of male satellites shows a strong relationship with female color,
#|    with numbers of satellites decreasing as color darkens. There is no evident relationship with 
#     worsening spine condition.
#| fig-asp: 0.4
#| 
library(patchwork)
p1  <- ggplot(crabs, aes(x = satell, y = color)) +
  geom_boxplot() +
  scale_color_openintro("two") +
  labs(y = "Color", x = NULL) +
  scale_x_continuous(breaks = seq(0, 16, 4)) +
  ggtitle("(a)")

p2  <- ggplot(crabs, aes(x = satell, y = spine)) +
  geom_boxplot() +
  scale_color_openintro("two") +
  labs(y = "Spine condition", x = "Number of satellites") +
  scale_x_continuous(breaks = seq(0, 16, 4)) +
  ggtitle("(b)")

p1/p2



```



### Two numerical variables {#sec-relationships-two-numerical}


 

```{r}
#| label: fig-crabs-width-weight-scatter
#| fig-cap: |
#|   A scatterplot showing the relationship between female crab width and weight in the crabs data.
#| fig-alt: |
#|    A scatterplot showing the relationship between female crab width and weight in the crabs data.
#|    Except for a few outliers, the relationship is linear   
ggplot(crabs, aes(x = width, y = weight))  +
  geom_point(alpha = 0.3, fill = IMSCOL["black", "full"], shape = 21) +
  labs(x = "Width (cm)", y = "Weight (kg)")


```

```{r}
#| label: fig-trees-height-carbon-scatter
#| fig-cap: |
#|   Two scatterplots showing the relationship between tree height and amount of carbon stored.
#| fig-subcap:
#|   - Scatterplot with both variables on original scale.
#|   - Scatterplot after square root transformation applied to tree height
#| fig-alt: |
#|   Two scatterplots showing the relationship between tree height and amount of carbon stored.
#|      In the original scale of measurement, the relationship is non-linear.  After transformation
#|      the relationship is nearly linear (despite the increased variability for tall trees) 
#| fig-width: 4
#| layout-ncol: 2
ggplot(portland_park_trees, aes(x = Tree_Height, y = Carbon_Storage_lb)) +
  geom_point(alpha = 0.3, fill = IMSCOL["black", "full"], shape = 21) +
  labs(x = "Tree Height (ft)", y = "Carbon Storage (lbs)")

ggplot(portland_park_trees, aes(x = Tree_Height, y = sqrt(Carbon_Storage_lb))) +
  geom_point(alpha = 0.3, fill = IMSCOL["black", "full"], shape = 21) +
  labs(x = "Tree Height (ft)", y = "Square root of Carbon Storage (lbs)")
```

Even relationships between just two variables can take many forms. [The World Bank Data Group](https://data.worldbank.org/) provides free and open access to indicators of economic and social development in countries around the world. The data `wdi_2022` in the [openintro](http://openintrostat.github.io/openintro) R package contains data for some of those indicators for the year 2022. @fig-wdi_2022-income-infant-mortality shows a \index{scatterplot} **scatterplot**

```{r}
#| label: fig-wdi_2022-income-infant-mortality
#| fig-cap: A scatterplot of infant mortality rate (on the y-axis) versus the 
#|    per-capita income for 217 countries as of 2022.  Infant mortality rate
#|    is measured as infant deaths before 1 year of age among 1,000 live births.
#| fig-alt: slightly modified text here

ggplot(wdi_2022, aes(x = gni_percap, y = infant_mortality_rate)) +
  geom_point(alpha = 0.3, fill = IMSCOL["black", "full"], shape = 21) +
  labs(
    x = "Income per capita",
    y = "Infant mortality rate"
  ) +
  geom_point(
    data = wdi_2022 |> 
    dplyr::filter(country == "Argentina"),
    size = 3, stroke = 2, color = IMSCOL["red", "full"], shape = 1
  ) +
  geom_text(
    data = wdi_2022 |> 
    dplyr::filter(country == "Argentina"),
    label = "Argentina", fontface = "italic",
    nudge_x = 21, nudge_y = -5, color = IMSCOL["red", "full"]
  ) +
  guides(color = FALSE) +
  geom_segment(
    data = wdi_2022 |> 
    dplyr::filter(country == "Argentina"),
    aes(
      x = 0, y = infant_mortality_rate, xend = gni_percap, 
      yend = infant_mortality_rate,
      color = IMSCOL["red", "full"]
    ), linetype = "dashed"
  ) +
  geom_segment(
    data = wdi_2022 |> 
    dplyr::filter(country == "Argentina"),
    aes(
      x = gni_percap, y = 0, xend = gni_percap, yend = infant_mortality_rate,
      color = IMSCOL["red", "full"]
    ), linetype = "dashed"
  ) +
  scale_x_continuous(labels = waiver()) +
  scale_y_continuous(labels = waiver())
```


## Case study: developmental disability support {#sec-developmental-disability}
